---
title             : "Learning to Interpret a Disjunction"
shorttitle        : "Learning Disjunction"

author: 
  - name          : "Masoud Jasbi"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "masoud_jasbi@fas.harvard.edu"
  - name          : "Akshay Jaggi"
    affiliation   : "2"
  - name          : "Michael C. Frank"
    affiliation   : "2"

affiliation:
  - id            : "1"
    institution   : "Harvard University"
  - id            : "2"
    institution   : "Stanford University"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  At first glance, children's word learning appears to be mostly a problem of learning words like *dog* and *run*. However, it is small words like *and* and *or* that enable the construction of complex combinatorial language. How do children learn the meaning of these function words? Using transcripts of parent-child interactions, we investigate the cues in child-directed speech that can inform the interpretation and acquisition of the connective *or*  which has a particularly challenging semantics. Study 1 finds that, despite its low overall frequency, children can use *or* close to parents' rate by age 4, in some speech acts. Study 2 uses annotations of a subset of parent-child interactions to show that disjunctions in child-directed speech are accompanied by reliable cues to the correct interpretation (exclusive vs. inclusive). We present a decision-tree model that learns from a handful of annotated examples to correctly predict the interpretation of a disjunction. These studies suggest that conceptual and prosodic cues in child-directed speech can provide information for the acquisition of functional categories like disjunction.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["JasbiJaggiFrank.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r global_options2, include=FALSE}
knitr::opts_chunk$set(fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)
```

```{r bootstrapping}
## for bootstrapping 95% confidence intervals
theta <- function(x,xdata) {mean(xdata[x])}
ci.low <- function(x) {
  quantile(bootstrap(1:length(x),1000,theta,x)$thetastar,.025)}
ci.high <- function(x) {
  quantile(bootstrap(1:length(x),1000,theta,x)$thetastar,.975)}
```

```{r load_packages}
library("papaja")
library(tidyverse)
library(ggthemes)
library(lubridate)
library(magrittr)
library(kableExtra)
library(bootstrap)
library(lme4)
library(lmerTest)
library(jpeg)
library(png)
library(DescTools)
```

# Introduction

<!--
Explain the puzzle of learning disjunction.

Basically the usage based approach has predicted that children should learn the exclusive meaning before the inclusive meaning. The nativist approach has predicted the opposite order.

Here we propose a cue-based approach which learns to interpret disjunction differently in different contexts. The account we propose is compatible with the findings of both the usage-based account and the nativist account.
-->
## Previous Literature

@morris2008logically investigated the use of *and* and *or* in child-directed speech and children's production between the ages of 2;0 and 5;0, using 240 transcriptions of audiotaped exchanges obtained in the CHILDES database. Each connective was analyzed with respect to its frequency, syntactic frame, meaning, and formal/informal use. With respect to frequency, the study found that overall, *and* is approximately 12.8 times more likely to be produced than *or*. There were a total of 6,459 connective uses: *and* was produced 5,994 times and *or* 465 times. 

As for the syntactic frames, instances of the connective use were coded as appearing in *statements* or *questions*. Morris reported that *and* appeared predominantly in statements (more than 90% of the time) while *or* was most common in questions (more than 85% of the time). For the meanings and uses of *and* and *or*, the study reported that for both adults and children, the dominant meanings of *and* and *or* were "conjunction" and "exclusive disjunction", respectively. This was taken to support the confirmed core-meaning hypothesis. There was also a significant increase in the mean number of different uses for *and* and *or*. *And* started with only the core conjunctive meaning at 2;0-2;6 and around the age of 3;0 to 4;0, children expanded it to two different uses on average. At 4;6-5, children were producing three different uses of *and*. The production of *or* started at around 3;0-3;6 with the "exclusive" meaning and expanded to 1.5 uses on average by 4;6-5;0.

However, this account faces an important issue. The conjunctive *and* and temporal/explanation *and*'s do not have the same syntactic status. The former often conjoins noun phrases while the latter two only conjoin clauses. We can have conjoined nouns phrases in utterances with 3 or 4 words while conjoined clauses require utterances longer than 4 words. How can a two-year-old with an average MLU of 1.5-2.5 words produce the temporal or explanation *and* which require conjoined clauses? It is possible that the increase in the number of words can be explained by syntactic rather than semantic development. The absence of non-conjunctive uses of *and* in the corpus data may only be a phenomenon in production and not comprehension. Even if children understand the meaning of temporal *and*, if they cannot yet produce conjoined clauses, temporal *and* will not be observable in corpus data. This question cannot be resolved from corpus evidence alone.

Utterances were also coded as informal or formal. Formal uses of connectives were defined as utterances about truth values or states of affairs. For example, a question like "does the dog have a tennis ball and a hockey puck?" to which the child answered with "No" was coded as formal. This is because the inquiry is about the state of the world. However, "I'd like peanut butter and jelly" was considered informal, presumably because it pertains to wants and desires. The study found that there are rare cases of formal use in parents' and children's speech. This is interpreted as evidence for the developmental claim that the connectives' formal or logical (or truth-conditional) interpretation is acquired later in development and is not part of the core meaning.

## Current Study

Here we present 4 studies. The first study focuses on the distribution of disjunction in adult-adult interactions. The second study looks at the distribution of disjunctionin parent-child interactions. The third study selects a sample of parent-child interactions and takes a closer look at the interpretations of disjunction in discourse context. The fourth study uses the annotations developed in the third study to train a computational model that learns the interpretation of a disjunction based on the cues that accompany it. We show that a learner that pays attention to the interpretive cues accompanying disjunction can learn to interpret it successfully as inclusive, exclusive, or even conjunctive.

# Study 1: Disjunction in adult-adult interactions

# Study 2: Disjunction in parent-child interactions

```{r importProcessedData}
wordCounts <- read_csv("connective_learning/2_processed_data/wordCounts.csv")
wordCounts_byAge <- read_csv("connective_learning/2_processed_data/wordCounts_byAge.csv")

freqTable_bySpeaker <- read.csv("connective_learning/2_processed_data/relfreq_bySpeaker.csv")

freqTable_bySpeakerSpeechAct <- read.csv("connective_learning/2_processed_data/relfreq_bySpeakerSpeechAct.csv")

cnctv_prop_bySpeechAct <- read_csv("connective_learning/2_processed_data/connective_prop_bySpeechAct.csv")

freqTable_bySpeechAct <- read.csv("connective_learning/2_processed_data/frequency_bySpeechAct.csv")

freqTable_byAge <- read.csv("connective_learning/2_processed_data/RelFreq_byAge.csv")
freqTable_byAgeSpeechAct <- read.csv("connective_learning/2_processed_data/RelFreq_byAgeSpeechAct.csv")

relFreq_bySpeaker <- read.csv("connective_learning/2_processed_data/relFreq_bySpeaker.csv")

relFerq_bySpeakerSpeechAct <- read.csv("connective_learning/2_processed_data/relFerq_bySpeakerSpeechAct.csv")

utteranceType_bySpeaker <- read_csv("connective_learning/2_processed_data/utteranceType_bySpeaker.csv")

utteranceType_byAge <- read_csv("connective_learning/2_processed_data/utteranceType_byAge.csv")

wordCounts_byCollection <- read_csv("connective_learning/2_processed_data/wordCounts_byCollection.csv")

corpus_density <- read_csv("connective_learning/2_processed_data/corpusDensity.csv")
child_density <- read_csv("connective_learning/2_processed_data/childDensity.csv")
```

```{r corpusStats}
corpora_info <- read_csv("connective_learning/1_raw_data/corpora_info.csv")

# convert the ages into years
corpora_info$target_child_age_years <-
  corpora_info$target_child_age %>% duration("days") %>% as.numeric("years")

# children's ages
Ages <- 
  corpora_info$target_child_age_years %>% unique() %>% na.omit()

# number of transcripts after age exclusion
n_transcripts <- corpora_info %>% filter(target_child_age_years < 6, target_child_age_years > 1) %>% select(transcript_id) %>% unique()

n_transcripts <- length(n_transcripts$transcript_id)

exclusions <- read_csv("connective_learning/2_processed_data/exclusions.csv")
```

## Methods

For samples of parents' and children's speech, this study used the online database [childes-db](childes-db.stanford.edu) and its associated R programming package `childesr` [@sanchez2018childes]. Childes-db is an online interface to the child language components of [TalkBank](https://talkbank.org/), namely [CHILDES](https://childes.talkbank.org/) [@macwhinney2000childes] and [PhonBank](https://phonbank.talkbank.org/). Two collections of corpora were selected: English-North America and English-UK. All word tokens were tagged for the following information: 1. The speaker role (mother, father, child), 2. the age of the child when the word was produced, 3. the type of the utterance the word appeared in (declarative, question, imperative, other), and 4. whether the word was *and*, *or*, or neither.

```{r corpusDensityPlot, fig.width=6, fig.height=2.5, fig.align="center", fig.env="figure", fig.cap="Frequency for all the words in the North America and UK corpora of CHILDES."}
corpus_density %>%
  ggplot(aes(x=target_child_age_months, y=word_count, color=speaker_role)) +
  geom_line(stat="identity") +
  facet_grid(.~collection_name) +
  labs(x="age (months)", y="word count") +
  theme_few() +
  theme(text = element_text(size=11, family="Times")) +
  scale_color_discrete(name = "Speaker Role")
```
<!--
```{r childDensityPlot, fig.width=5, fig.height=2.5, fig.align="center", fig.env="figure", fig.cap="The number of children represented at different ages in the North America and UK corpora in CHILDES."}
child_density %>%
  ggplot(aes(x=target_child_age_months, y=child_count)) +
  geom_bar(stat="identity") +
  facet_grid(.~collection_name) +
  labs(x="age (months)", y="Number of Children") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```
-->
### Exclusion Criteria
First, observations (tokens) that were coded as unintelligible were excluded (N = `r format(exclusions$Unintelligible, big.mark=",")`). Second, observations that had missing information on children's age were excluded (N = `r format(exclusions$missing, big.mark=",")`). Third, observations outside the age range of 1 to 6 years were excluded (N = `r format(exclusions$age_ex, big.mark=",")`). This exclusion was because we were interested in the 1 to 6 years old age range and there was not much data outside this age range either. <!--Figure \@ref(fig:ageDistPlot) shows the distribution of transcripts based on the age of the child at recording time.The mean age is shown with a red vertical line (Mean Age = `r round(mean(Ages),2)`, SD = `r round(sd(Ages),2)`).--> The collection contained the speech of `r exclusions$n_children` children and their parents after the exclusions. 

### Procedure
Each token was marked for the utterance type that the token appeared in. This study grouped utterance types into four main categories: "declarative", "question", "imperative", and "other". Utterance type categorization followed the convention used in the [TalkBank manual](https://talkbank.org/manuals/CHAT.html#_Toc486414422). The utterance types are similar to sentence types (declarative, interrogative, imperative) with one exception: the category "question" consists of interrogatives as well as rising declaratives (i.e. declaratives with rising question intonation). In the transcripts, declaratives are marked with a period, questions with a question mark, and imperatives with an exclamation mark. It is important to note that the manual also provides [terminators for special-type utterances](https://talkbank.org/manuals/CHAT.html#_Toc486414431). Among the special type utterances, this study included the following in the category "questions": trailing off of a question, question with exclamation, interruption of a question, and self-interrupted question. The category imperatives also included "emphatic imperatives". The rest of the special type utterances such as "interruptions" and "trailing off" were included in the category "other".     
<!--
```{r ageDistPlot, fig.asp=0.5, fig.width=5, fig.height=3, fig.pos="center", fig.cap="Distribution of children's ages at recording times. Mean age is shown using a red vertical line."}
  par(family = "Times")
  hist(Ages, breaks = 50) 
  abline(v=mean(Ages),col="red", xlim=c(0,10))
  axis(side=1, at=seq(0,15, 1), labels=seq(0,15, 1))
```
-->

## Properties of CHILDES Corpora

```{r wordCount}
count_table <-
  wordCounts %>%
  select(-X1) %>%
  spread(word, counts) %>%
  mutate(total = and + or + other) %>%
  select(-other)

total_words <- sum(count_table$total)
```

In this section, I report some results on the distribution of words and utterances among the speakers in our collection of corpora. The collection contained `r format(total_words, big.mark = ",")` words. Table (\@ref(tab:countTable)) shows the total number of *and*'s, *or*'s, and words in the speech of children, fathers, and mothers. The collection contains  `r round(count_table$total[2]/count_table$total[1],1)` times more words for mothers compared to fathers and `r round(count_table$total[2]/count_table$total[3],1)` more words for mothers compared to children. Therefore, the collection is more representative of the mother-child interactions than father-child interactions. Compared to *or*, the word *and* is `r round(count_table$and[2]/count_table$or[2],1)` times more likely in the speech of mothers, `r round(count_table$and[1]/count_table$or[1],1)` times more likely in the speech of fathers, and `r round(count_table$and[3]/count_table$or[3],1)` times more likely in the speech of children. Overall, *and* is `r round(sum(count_table$and)/sum(count_table$or),2)` times more likely than *or* in this collection which is close to the rate reported by @morris2008logically who used a smaller subset of CHILDES. He extracted 5,994 instances of *and* and 465 instances of *or* and found that overall, *and* was 12.89 times more frequent than *or* in parent-child interactions.

```{r countTable}
kable(count_table, caption = "Number of \\textit{and}'s, \\textit{or}'s, and the total number of words in the speech of children and their parents in English-North America and English-UK collections after exclusions.", format.args = list(big.mark = ','), col.names = c("Speaker Role", "and", "or", "total"))
```

Figure \@ref(fig:wordsByAge) shows the number of words spoken by parents and children at each month of the child's development. The words in the collection are not distributed uniformly and there is a high concentration of data between the ages of 20 and 40 months (around 2 to 3 years of age). There is also a high concentration around 60 months (5 years of age). The speech of fathers shows a relatively low word-count across all ages. Therefore, in our analyses we should be more cautious in drawing conclusions about the speech of fathers generally, and the speech of mothers and children after age 5.
<!--
```{r wordsByAge, fig.env="figure", fig.align="center", fig.width=5, fig.height=2.5, fig.cap="The number of words in the corpora for parents and children in each month of children's development."}
wordCounts_byAge %>%
  ggplot(aes(x=target_child_age_months, y=count, color=speaker_role)) +
  geom_line(size=0.8) +
  labs(x="age (months)", y="number of words") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  theme_few() +
  theme(text = element_text(size=11, family="Times")) +
  scale_color_discrete(name = "Speaker Role")
```
-->
The distribution of function words is sensitive to the type of utterance or more broadly the type of speech act produced by speakers. For example, it is not surprising to hear a parent say "go to your room" but a child saying the same to a parent is unexpected. If a function word commonly occurs in such speech acts, it is unlikely to be produced by children, even though they may understand it very well. Therefore, it is important to check the distribution of speech acts in corpora when studying different function words. Since it is hard to classify and quantify speech acts automatically, here I use utterance type as a proxy for speech acts. I investigate the distribution of declaratives, questions, and imperatives in this collection of corpora on parent-child interactions. Figure \@ref(fig:totalUtteranceTypePlot) shows the distribution of different utterance types in the speech of parents and children. Overall, most utterances are either declaratives or questions, and there are more declaratives than questions in this collection. While mothers and fathers show similar proportions of declaratives and questions in their speech, children produce a lower proportion of questions and higher proportion of declaratives than their parents.

```{r totalUtteranceTypePlot, fig.env="figure", fig.align="center", fig.cap="The proportion of declaratives and questions in children's and parents' utterances."}
utteranceType_bySpeaker %>%
#  filter(type == "declarative" | type == "question") %>%
  ggplot(aes(x=speaker_role, y=utteranceType_ppc, fill=speech_act)) + 
  geom_bar(stat="identity") + 
#  scale_fill_discrete(name = "Speech Act") +
  labs(x="Speaker Role", y="Proportion (%)") +
  theme_few() + theme(text = element_text(size = 10, family="Times"))
```

Figure \@ref(fig:utteranceTypeByAgePlot) shows the developmental trend of declaratives and questions between the ages of one and six. Children start with only producing declaratives and add non-declarative utterances to their repertoire gradually until they get closer to the parents' rate around the age six. They also start with very few questions and increase the number of questions they ask gradually. It is important to note that the rates of declaratives and questions in children's speech do not reach the adult rate. These two figures show that parent-child interactions are asymmetric. Parents ask more questions and children produce more declaratives. This asymmetry also interacts with age: the speech of younger children has a higher proportion of declaratives than older children.

```{r utteranceTypeByAgePlot, fig.width=5.5, fig.height=2.5, fig.cap = "Proportion of declaratives to questions in parent-child interactions by age."}
utteranceType_byAge %>%
  filter(speech_act == "declarative" | speech_act == "question") %>%
  ggplot(aes(x=target_child_age_months, y=utteranceType_ppc, shape=speaker_role, color = speaker_role)) +
  geom_point(aes(), size=0.6) + 
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +  
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue")) + 
  labs(x = "age (months)", y="Proportion (%)") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  facet_grid(.~speech_act) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

```{r utteranceTypeByAgePlot2, eval=FALSE}
utteranceType_byAge
utteranceType_byAge$Speaker <- "Parents"
utteranceType_byAge[utteranceType_byAge$speaker_role=="Target_Child",]$Speaker <- "Children"

utteranceType_byAge %>%
  filter(speech_act == "declarative" | speech_act == "question") %>%
  ggplot(aes(x=target_child_age_months, y=utteranceType_ppc, shape=Speaker, color = Speaker)) +
  geom_point(aes(), size=0.6) + 
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +  
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  labs(x = "age (months)", y="Proportion (%)") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  facet_grid(.~speech_act) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

The frequency of function words such as *and* and *or* may be affected by such conversational asymmetries if they are more likely to appear in some utterance types than others. Figure \@ref(fig:CnctPropbySpeechAct) shows the proportion of *and*'s and *or*'s that appear in different utterance types in parents' and children's speech. In parents' speech, *and* appears more often in declaratives (around 60% in declaratives and 20% in questions). On the other hand, *or* appears  more often in questions than declaratives, although this difference is small in mothers. In children's speech, both *and* and *or* appear most often in declaratives. However, children have a higher proportion of *or* in questions than *and* in questions. 

The differences in the distribution of utterance types can affect our interpretation of the corpus data on function words such as *and* and *or* in three ways. First, since the collection contains more declaratives than questions, it may reflect the frequency and diversity of function words like *and* that appear in declaratives better. Second, since children produce more declaratives and fewer questions than parents, we may underestimate children's knowledge of function words like *or* that are frequent in questions. Third, given that the percentage of questions in the speech of children increases as they get older, function words like *or* that are more likely to appear in questions may appear infrequent in the early stages and more frequent in the later stages of children's development. In other words, function words like *or* that are common in questions may show a seeming delay in production which is possibly due to the development of questions in children's speech. Therefore, in studying children's productions of function words, it is important to look at their relative frequencies in different utterance types as well as the overall trends. This is the approach I pursue in the next section.

```{r CnctPropbySpeechAct, fig.env="figure", fig.align="center", fig.width= 6, fig.height=3, fig.cap="The proportion of \\textit{and} and \\textit{or} in different utterance types in the speech of parents and children."}
cnctv_prop_bySpeechAct %>%
  filter(word != "other") %>%
  ggplot(aes(x=speech_act, y=connective_pct, fill=speech_act)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~speaker_role) + 
  theme_few() +
  geom_errorbar(aes(ymin=lower_pct, ymax=upper_pct), width=0.1) + 
  labs(x="", y="Proportion (%)") + 
#  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue", "gray")) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1), text = element_text(size=11, family="Times")) +
  guides(fill=FALSE)
```

<!--
### Properties of the Switchboard Corpus
-->
## Results {#study1results}

First, I consider the overall distribution of *and* and *or* in the corpora and then look closer at their distributions in different utterance types. Figure \@ref(fig:freqTableBySpeakerPlot) shows the frequency of *and* and *or* relative to the total number of words produced by each speaker (i.e. fathers, mothers, and children). The y-axes show relative frequency per thousand words. It is also important to note that the y-axes show different ranges of values for *and* vs. *or*. This is due to the large difference between the relative frequencies of these connectives. Overall, *and* occurs around 15 times per thousand words but *or* only occurs 3 times per 2000 words in the speech of parents and around 1 time every 2000 words in the speech of children. Comparing the relative frequency of the connectives in parents' and children's speech, we can see that overall, children and parents produce similar rates of *and* in their interactions. However, children produce fewer *or*'s than their parents. 

```{r freqTableBySpeakerPlot, fig.env="figure", fig.align="center", fig.width=3, fig.height=2.5, fig.cap="The relative frequency of \\textit{and/or} in the speech of fathers, mothers, and children. 95\\% binomial proportion confidence intervals calculated using Agresti-Coull's approximate method."}
freqTable_bySpeaker %>%
  filter(word != "other") %>%
  ggplot(aes(x=speaker_role, y=ppt, fill=speaker_role)) + 
  geom_bar(stat="identity", width = 0.7) + 
  facet_grid(word~., scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin = ppt_lower, ymax=ppt_upper), width=0.2) +
  labs(x="", y="Relative Frequency (per thaousand)") + 
  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue")) + 
  guides(fill=FALSE) + 
  theme(text = element_text(size=11, family="Times"))
```

```{r freqTablebySpeechAct2, eval=FALSE}
freqTable_bySpeaker$Speaker <- "Parents"
freqTable_bySpeaker[freqTable_bySpeaker$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_bySpeaker2 <-
freqTable_bySpeaker %>%
  group_by(Speaker, word) %>%
  summarize(count=sum(count), total=sum(total))

# calculating the confidence intervals
conf_ints <- 
  binom.confint(freqTable_bySpeaker2$count, freqTable_bySpeaker2$total, conf.level = 0.95, methods = "exact") %>%
  rename(total = "n", count="x", rel_freq = "mean") %>%
  select(-method)

#joining the confidence interval table and the proportion table
freqTable_bySpeaker2 %<>%
  full_join(conf_ints, by=c("count","total")) %>%
  mutate(ppt = rel_freq*1000, upper_ppt=upper*1000, lower_ppt=lower*1000)

freqTable_bySpeaker2 %>%
  filter(word != "other") %>%
  ggplot(aes(x=Speaker, y=ppt, fill=Speaker)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~., scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen", "darkblue")) + 
  theme(text = element_text(size=14, family="Times")) +
  guides(fill=FALSE)
```
Next we look at the relative frequencies of *and* and *or* in parents and children's speech during the course of children's development. Figure \@ref(fig:agePlot) shows the relative frequencies of *and* and *or* in parents' and children's speech between 12 and 72 months  (1-6 years). Production of *and* in parents' speech seems to be relatively stable and somewhere between 10 to 20 *and*'s per thousand words over the course of children's development. For children, they start producing *and* between 12 and 24 months, and show a sharp increase in their production until they reach the parent level between 30 to 36 months of age. Children stay close to the parents' production level between 36 and 72 months, possibly surpassing them a bit at 60 months -- although as stated in the previous section, we should be cautious about patterns after 60 months due to the small amount of data in this period. For *or*, parents produce between 1 to 2 *or*'s every thousand words and mothers show a slight increase in their productions between 12 to 36 months. Children start producing *or* between 18 to 30 months of age. They show a steady increase in their productions of *or* until they get close to 1 *or* per thousand words at 48 months (4 years) and  stay at that level until 72 months (6 years). 

Children's productions of *and* and *or* show two main differences. First, the onset of *or* production is later than that of *and*. Children start producing *and* around 1 to 1.5 years old while *or* productions start around 6 months later. Second, children's *and* production shows a steep rise and reaches the parent level of production at three-years old. For *or*, however, the rise in children's production level does not reach the parent level even though it seems to reach a constant level between the ages of 4 and 6 years. 

Not reaching the parent level of *or* production does not necessarily mean that children's understanding of *or* has not fully developed yet. It can also be due to the nature of parent-child interactions. For example, since parents ask more questions than children and *or* appears frequently in questions, parents may have a higher frequency of *or*. There are two ways of controlling for this possibility. One is to research children's speech to peers. Unfortunately such a large database of children's speech to peers is not currently available for analysis. Alternatively, we can look at the relative frequencies and developmental trends within utterance types such as declaratives and questions to see if we spot different developmental trends. This is what I pursue next.

```{r agePlot, fig.env="figure", fig.align="center", fig.width=4.5, fig.height=3.5, fig.cap="The monthly relative frequency of \\textit{and/or} in parents and children's speech between 12 and 72 months (1-6 years)."}
freqTable_byAge %>%
  filter(word!="other") %>%
  ggplot(aes(target_child_age_months, ppt, shape = speaker_role, color=speaker_role)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~., scales="free_y") +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "Age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme_few() + guides(shape=FALSE) +
  theme(text = element_text(size=11, family = "Times"))
```

```{r agePlot2, eval=FALSE}
freqTable_byAge$Speaker <- "Parents"
freqTable_byAge[freqTable_byAge$speaker_role=="Target_Child",]$Speaker <- "Children"


freqTable_byAge %>%
  filter(word!="other") %>%
  ggplot(aes(target_child_age_months, ppt, shape = Speaker, color=Speaker)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~., scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "Age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  theme_few() + guides(shape=FALSE) +
  theme(text = element_text(size=11, family = "Times"))
```

Figure \@ref(fig:freqTablebySpeechAct) shows the relative frequency of *and* and *or* in declaratives, questions, and imperatives. *And* has the highest relative frequency in declaratives while *or* has the highest relative frequency in questions. Figure \@ref(fig:ageSpeechActPlot) shows the developmental trends of the relative frequencies of *and* and *or* in questions and declaratives. Comparing *and* in declaratives and questions, we see that the onset of *and* productions are slightly delayed for questions but in both declaratives and questions, *and* productions reach the parent level around 36 months (3 years). For *or*, we see a similar delay in questions compared to declaratives. Children start producing *or* in declaratives at around 18 months but they start producing *or* in questions at 24 months. Production of *or* increases in both declaratives and questions until it seems to reach a constant rate in declaratives between 48 and 72 months. The relative frequency of *or* in questions continues to rise until 60 months. Comparing figures \@ref(fig:agePlot) and \@ref(fig:ageSpeechActPlot), we see that children are closer to the adult rate of production in declaratives than questions. The large difference between parents and children's production of *or* in figure \@ref(fig:agePlot) may partly be due to the development of *or* in questions. Overall the results show that children have a substantial increase in their productions of *and* and *or* between 1.5 to 4 years of age. Therefore, it is reasonable to expect that early mappings for the meaning and usage of these words develop in this age range. 

```{r freqTablebySpeechAct, fig.align="center", fig.width=5, fig.height=3, fig.cap="Relative frequency of \\textit{and/or} in declaratives, imperatives, and interrogatives for parents and children "}
freqTable_bySpeakerSpeechAct %>%
  filter(word != "other", speech_act!="other") %>%
  ggplot(aes(x=speech_act, y=ppt, fill=speaker_role)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~speaker_role, scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1), text = element_text(size=11, family="Times")) +
  guides(fill=FALSE)
```

```{r freqTablebySpeechAct22, eval=FALSE}
freqTable_bySpeakerSpeechAct$Speaker <- "Parents"
freqTable_bySpeakerSpeechAct[freqTable_bySpeakerSpeechAct$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_bSpeakerSpeechAct2 <-
freqTable_bySpeakerSpeechAct %>%
  group_by(Speaker, word, speech_act) %>%
  summarize(count=sum(count), total=sum(total))

# calculating the confidence intervals
conf_ints <- 
  binom.confint(freqTable_bSpeakerSpeechAct2$count, freqTable_bSpeakerSpeechAct2$total, conf.level = 0.95, methods = "exact") %>%
  rename(total = "n", count="x", rel_freq = "mean") %>%
  select(-method)

#joining the confidence interval table and the proportion table
freqTable_bSpeakerSpeechAct2 %<>%
  full_join(conf_ints, by=c("count","total")) %>%
  mutate(ppt = rel_freq*1000, upper_ppt=upper*1000, lower_ppt=lower*1000)

freqTable_bSpeakerSpeechAct2 %>%
  filter(word != "other", speech_act!="other") %>%
  ggplot(aes(x=speech_act, y=ppt, fill=Speaker)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~Speaker, scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen", "darkblue")) + 
  theme(text = element_text(size=14, family="Times")) +
  guides(fill=FALSE)
```

```{r ageSpeechActPlot, fig.env="figure", fig.align="center", fig.width=6, fig.height=4, fig.cap="Relative frequency of \\textit{and/or} in declaratives and questions for parents and childern between the child-age of 12 and 72 months (1-6 years)."}
freqTable_byAgeSpeechAct %>%
  filter(word!="other", speech_act!="other", speech_act!="imperative") %>%
  ggplot(aes(target_child_age_months, ppt, shape = speaker_role, color=speaker_role)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~speech_act, scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme_few() +
  theme(text = element_text(size=11, family="Times")) + 
  scale_shape_discrete(name = "Speaker Role")
```

```{r ageSpeechActPlot2, eval=FALSE}
freqTable_byAgeSpeechAct$Speaker <- "Parents"
freqTable_byAgeSpeechAct[freqTable_byAgeSpeechAct$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_byAgeSpeechAct %>%
  filter(word!="other", speech_act!="other", speech_act!="imperative") %>%
  ggplot(aes(target_child_age_months, ppt, shape = Speaker, color=Speaker)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~speech_act, scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
#  guides(shape=FALSE, color=FALSE)
```

## Discussion {#study1discussion}

The goal of this study was to explore the frequency of *and* and *or* in parents and children's speech. The study found three differences. First, it found a difference between the overall frequency of *and* and *or* in both parents and children. *And* was about 10 times more frequent than *or* in the speech of parents and 30 times more likely in the speech of children. Second, the study found a difference between parents' and children's productions of *or*. Relative to the total number of words spoken by parents and children between the ages of 1 and 6 years, both children and parents produce on average 15 *and*'s every 1000 words. Therefore, children match parents' rate of *and* production overall. This is not the case for *or* as parents produce 3 *or*'s every 2000 words and children only 1 every 2000 words. Third, the study found a developmental difference between *and* and *or* as well. The study found that the onset of production is earlier for *and* than *or*. In the monthly relative frequencies of *and* and *or* in the speech of parents and children, the study also found that children reach the parents' level of production for *and* at age 3 while *or* does not reach the parents' level even at age 6. 

What causes these production differences? The first difference -- that *and* is far more frequent than *or* -- is not surprising or limited to child-directed speech. *And* is useful in a large set of contexts from conjoining elements of a sentence to connecting discourse elements or even holding the floor and delaying a conversational turn. In comparison, *or* seems to have a more limited usage. The second and the third differences -- namely that children produce fewer *or*'s than parents, and that they produce *and* and reach their parents rate earlier than *or* -- could be due to three factors. First, production of *and* develops and reaches the parents' rate earlier possibly because it is much more frequent than *or* in children's input. Previous research suggests that within the same syntactic category, words with higher frequency in child-directed speech are acquired earlier [@goodman2008does]. The conjunction word *and* is at least 10 times more likely than *or* so earlier acquisition of *and* is consistent with the effect of frequency on age of acquisition. Second, research on concept attainment has suggested that the concept of conjunction is easier to conjure and possibly acquire than the concept of disjunction. In experiments that participants are asked to detect a pattern in the classification of cards, participants can detect a conjunctive classification pattern faster than a disjunctive one [@neisser1962hierarchies]. Therefore, it is possible that children learn the meaning of *and* faster and start to produce it earlier but they need more time to figure out the meaning and usage of *or*.

A third possibility is that the developmental difference between *and* and *or* is mainly due to the asymmetric nature of parent-child interactions and the utterance types that each role in this interaction requires. For example, this study found that parents ask more questions of children than children do of parents. It also found that *or* is much more frequent in questions than *and* is. Therefore, parent-child interaction provides more opportunities for parents to use *or* than children. In the next study we will discuss several constructions and communicative functions that are also more appropriate for the role of parents. For example, *or* is often used to ask what someone else wants like "do you want apple juice or orange juice?" or for asking someone to clarify what they said such as "did you mean ball or bowl?". Both of these constructions are more likely to be produced by a parent than a child. *Or* is also used to introduce examples or provide definitions such as "an animal, like a rabbit, or a lion, or a sheep". It is very unlikely that children would use such constructions to define terms for parents! Furthermore, such constructions also reveal their own developmental trends. For example, the study found that children start by almost entirely producing declaratives and increase their questions until at age 4 to 6, about 10% of their utterances are questions. Therefore, children's ability to produce *or* in a question is subject to the development of questions themselves. More generally, the developmental difference between *and* and *or* may also be due to a difference in the development of other factors that production of *and* and *or* rely on, such as the development of constructions with specific communicative functions like unconditionals (Whether X or Y, discussed in Chapter \@ref(sempragLit)). In future research, it will be important to establish the extent to which each of these potential causes -- frequency, conceptual complexity, and the development of other factors such as utterance type or constructions with specific communicative functions --  contribute to the developmental differences in the production of conjunction and disjunction. 

# Study 3: Interpretations of disjunction in child-directed speech

Previous study reported on the frequencies of disjunction in parents and children's speech production. To help us better understand children's linguistic input, this study offers a close examination of the interpretations that *and* and *or* have in child-directed speech. It had two main goals. First, to replicate the finding of @morris2008logically and second, to identify any cues in children's input that might help them learn the interpretations of disjunction in English.

## Methods

```{r importAnnotations}
# Import annotation data
connective_annotations <- read.csv("connective_learning/3_providence_annotations/providence_merged.csv")

# calculate the ages of children at the time of recording in years
connective_annotations$age_years <- interval(mdy(connective_annotations$b_date), mdy(connective_annotations$r_date))/years(1)

# record the age in months
connective_annotations$age_months <- floor(connective_annotations$age_years * 12)

# Recode interpretation
connective_annotations$connective_meaning %<>% recode(`XNOR` = "IFF", `NPQ`="NAB")
# Recode intonation levels
connective_annotations$intonation %<>% recode(`0` = "flat", `1` = "rise", `2`="rise-fall")
# Recode Answer level "no answer"
connective_annotations$answer %<>% recode(`0` = "No Answer")

#Make speech acts and utterance type categories case insensitive
connective_annotations$speech_act %<>% tolower()
connective_annotations$utterance_type %<>% tolower()
connective_annotations$speech_act %<>% tolower()

# store disjunctions separetely
disjunctions <- connective_annotations %>% filter(annotation=="OR")
conjunctions <- connective_annotations %>% filter(annotation=="AND")

# the number of *and* and *or* examples annotated
total_annotaitons<-
connective_annotations %>%
  group_by(annotation) %>%
  summarize(counts=n())
```

This study used [the Providence corpus](https://phonbank.talkbank.org/browser/index.php?url=Eng-NA/Providence/) [@demuth2006word] available via the [PhonBank](https://phonbank.talkbank.org) section of [the TalkBank.org archive](https://talkbank.org/). The corpus was chosen because of its relatively dense data on child-directed speech as well as the availability of audio and video recordings that would allow annotators access to the context of the utterance. The corpus was collected between 2002 and 2005 in Providence, Rhode Island. Table \@ref(tab:providence)  reports the name, age range, and the number of recording sessions for the participants in the study. All children were monolingual English speakers and were followed between the ages of 1 and 4 years. Based on Study 2, this is the age range when children develop their early understanding or mappings for the meanings of *and* and *or*. The corpus contains roughly biweekly hour-long recordings of spontaneous parent-child interactions, with most recordings being of mother-child interactions. The corpus consists of a total of 364 hours of speech.

|Name	| Age Range |	Sessions |
|:-----:|:-----:|:----------:|
|Alex|1;04.28-3;05.16 |51|
|Ethan|0;11.04-2;11.01 |50|
|Lily|1;01.02-4;00.02|80|
|Naima|0;11.27-3;10.10|88|
|Violet|1;02.00-3;11.24|51|
|William|1;04.12-3;04.18|44|
Table: (\#tab:providence) Information on the participants in the Providence Corpus. Ethan was diagnosed with Asperger's syndrome and therefore was excluded from this study.

###Exclusion Criteria 
We excluded data from Ethan since he was diagnosed with Asperger's Syndrome at age 5. We also excluded all examples found in conversations over the phone, adult-adult conversations, and utterances heard from TV or radio. We did not count such utterances as child-directed speech. We excluded proper names and fixed forms such as "Bread and Circus" (name of a local place) or "trick-or-treat" from the set of examples to be annotated. The rationale here was that such forms could be learned and understood with no actual understanding of the connective meaning. We counted multiple instances of *or* and *and* within the same disjunction/conjunction as one instance. The reasoning was that, in a coordinated structure, the additional occurrences of a connective typically did not alter the annotation categories, and most importantly the interpretation of the coordination. For example, there is almost no difference between "cat, dog, and elephant" versus "cat and dog and elephant" in interpretation. In short, we focused on the "coordinated construction" as a unit rather than on every separate instance of *and* and *or*. Instances of multiple connectives in a coordination were rare in the corpus.

###Procedure 
All utterances containing *and* and *or* were extracted using [the CLAN software](http://alpha.talkbank.org/clan/) and automatically tagged for the following: (1) the name of the child; (2) the transcript address; (3) the speaker of the utterance (father, mother, or child); (4) the child's birth date, and (5) the recording date. Since the focus of the study was mainly on disjunction, we annotated instances of *or* in all the child-directed speech from the earliest examples to the latest ones found. Given that the corpus contained more than 10 times the number of *and*'s than *or*'s, we randomly sampled 1000 examples of *and* to match 1000 examples of *or*. Here we report the results on `r nrow(conjunctions)` examples of *and* and `r nrow(disjunctions)` examples of *or*.

### Annotation Categories

Every extracted instance of *and* and *or* was manually annotated for 7 categories: 1. Connective Interpretation 2. Intonation Type 3. Utterance Type  4. Syntactic Level 5. Conceptual Consistency 6. Communicative Function and 7. Answer Type. In what follows, I briefly explain how each annotation category was defined. Further details and examples are provided in the appendix section.

#### Connective Interpretation 
This annotation category was the dependent variable of the study. Annotators listened to coordinations such as "A or B" and "A and B", and decided the intended interpretation of the connective with respect to the truth of A and B. We used the sixteen binary connectives shown in Figure \@ref(fig:logicalConnectives) as the space of possible connective interpretations. Annotators were asked to consider the two propositions raised by the coordinated construction, ignoring the connective and functional elements such as negation and modals. Consider the following sentences containing *or*: "Bob plays soccer or tennis" and "Bob doesn't play soccer or tennis". Both discuss the same two propositions: A. Bob playing soccer, and B. Bob playing tennis. However, the functional elements combining these two propositions result in different interpretations with respect to the truth of A and B. In "Bob plays soccer or tennis" which contains a disjunction, the interpretation is that Bob plays one or possibly both sports (inclusive disjunction IOR). In "Bob doesn't play soccer or tennis" which contains a negation and a disjunction, the interpretation is that Bob plays neither sport (NOR). For connective interpretations, the annotators first reconstructed the coordinated propositions without the connectives or negation and then decided which propositions were implied to be true/false.

This approach is partly informed by children's development of function and content words. Since children acquire content words earlier than functions words, we assumed that when learning logical connectives, they better understand the content of the propositions being coordinated rather than the functional elements involved in building the coordinated construction. For example, considering the sentences "Bob doesn't play soccer or tennis" without its function words as "Bob, play, soccer, tennis", one can still deduce that there are two relevant propositions: Bob playing soccer, and Bob playing tennis. However, the real challenge is to figure out what is being communicated with respect to the truth of these two propositions. If the learner can figure this out, then the meaning of the functional elements can be reverse engineered. For example, if the learner recognizes that "Bob plays soccer or tennis" communicates that one or both propositions are true (IOR), the learner can associate this interpretation to the unknown element *or*. Similarly, if the learner recognizes the interpretation of "Bob doesn't play soccer or tennis" as neither proposition is true (NOR), they can associate this interpretation to the co-presence of *or* and *doesn't*. Table \@ref(tab:connectiveInterpretaion) in the appendix section reports the connective interpretations found in our annotations as well as some examples for each interpretation.

####Intonation Type
Annotators listened to the utterances and decided whether the intonation contour on the coordination was flat, rise, or rise-fall. Table \@ref(tab:intonationTypes) in the appendix shows the definitions and examples for these intonation types. In order to judge the intonation of the sentence accurately, annotators were asked to construct all three intonation contours for the sentence and see which one is closer to the actual intonation of the utterance. For example, to judge the sentence "do you want orange juice$\uparrow$ or apple juice$\downarrow$?", they reconstructed the sentence with the prototypical flat, rising, and rise-fall intonations and checked to see which intonation is closer to the actual one. It is important to note that while these three intonation contours provide a good general classification, there is a substantial degree of variation as well as a good number of subtypes within each intonation type.

####Utterance Type
Annotators decided whether an utterance was an instance of a declarative, an interrogative, or an imperative. Occasionally, we found examples with different utterance types for each coordinand. For example, the mother would say "put your backpack on and I'll be right back", where the first cooridnand is an imperative and the second a declarative. Such examples were coded for both utterance types with a dash inbetween: imperative-declarative. Table \@ref(tab:utteranceTypes) in the appendix provides the definitions and examples for each utterance type.

####Syntactic Level 
For this annotation category, annotators decided whether the coordination was at the clausal level or at the sub-clausal level. Clausal level was defined as sentences, clauses, verb phrases, and verbs. Coordination of other categories was coded as sub-clausal. This annotation category was introduced to check the hypothesis that the syntactic category of the coordinands may influence the interpretation of a coordination. The intuition was that a sentence such as "He drank tea or coffee" is less likely to be interpreted as exclusive than "He drank tea or he drank coffee." The clausal vs. sub-clausal distinction was inspired by the fact that in many languages, coordinators that connect sentences and verb phrases are different lexical items than those that connect nominal, adjectival, or prepositional phrases [see @haspelmath2007]. 

####Conceptual Consistency
Propositions that are connected by words such as *and* and *or* often stand in complex conceptual relations with each other. For conceptual consistency, annotators decided whether the propositions that make up the coordination can be true at the same time or not. If the two propositions could be true at the same time they were marked as consistent. If the two propositions could not be true at the same time and resulted in a contradiction, they were marked as inconsistent. Our annotators used the following diagnostic to decide the consistency of the disjuncts: Two disjuncts were marked as inconsistent if replacing the word *or* with *and* produced a contradiction. For example, changing "the ball is in my room *or* your room" to "the ball is in my room *and* your room" produces a contradiction because a ball cannot be in two rooms at the same time[^1]. 

[^1]:This criterion is quite strict. In many cases, the possibility of both propositions being true is ruled out based on prior knowledge and expectations of the situation. For example, when asking people whether they would like tea or coffee, it is often assumed and expected that people choose one or the other. However, wanting to drink both tea and coffee is not conceptually inconsistent. It is just very unlikely. Our annotations of consistency are very conservative in that they still consider such unlikely cases as consistent. Relaxing this criterion to capture the unlikely cases may increase exclusivity inferences that are caused by alternatives that are considered unlikely to co-occur.
<!--
Second, there are other more complex relations between coordinated propositions that we have not coded for. For example, coordinated propositions sometimes stand in a causal relation (e.g. the cup fell and broke) or sometimes in a temporal relation (e.g. she brushed her teeth and went to bed), among many more. It is quite feasible to assume that the rich conceptual structure of these propositions help children learn the meaning and use of connectives such as *and*, *or*, *if*, *therefore*, etc. It is possible to develop a more detailed investigation on the relation between propositions and how that affects the acquisition of connective meaning generally. However, in this study we mainly focus on conceptual consistency of the coordinated propositions and how that affects the acquisition of *and* and *or*.
-->
It is also important to note that if the coordinands are inconsistent, this does not necessarily means that the connective interpretation must be exclusive. For example, in a sentence like "you could stay here or go out", the alternatives "staying here" and "going out" are inconsistent. Yet, the overall interpretation of the connective could be conjunctive: you could stay here AND you could go out. The statement communicates that both possibilities hold. This pattern of interaction between possibility modals like *can* and disjunction words like *or* are often discussed under the label "free-choice inferences" in the semantics and pragmatics literature [@von1968essay; @kamp1973free]. Another example is unconditionals such as "Ready or not, here I come!". The coordinands are contradictions: one is the negation of the other. However, the overall interpretation of the sentences is that in both cases, the speaker is going to come.

####Communicative Functions
This study constructed a set of categories that captured particular usages or communicative functions of the words *or* and *and*. They include descriptions, directives, preferences, identifications, definitions and examples, clarifications, repairs, and a few others shown with examples in Table \@ref(tab:speechActs) in the appendix section. These communicative functions were created using the first 100 examples and then they were used for the classification of the rest of the examples. Some communicative functions are general and some are specific to coordination. For example, directives are a general class while conditionals (e.g. Put that out of your mouth, or I'm gonna put it away) are more specific to coordinated constructions. It is also important to note that the list is not unstructured. Some communicative functions are subtypes of others. For example, "identifications" and "unconditionals" are subtypes of "descriptions" while "conditionals" are a subtype of directives. Furthermore, "repairs" seem parallel to other categories in that any type of speech can be repaired. We do not fully explore the details of these functions in this study but such details matter for a general theory of acquisition that makes use of the speaker's communicative intentions as early coarse-grained communicative cues for the acquisition of fine-grained meaning such as function words.

####Answer Type
Whenever a parent's utterance was a polar question, the annotators coded the utterance for the type of response it received from the children. Table \@ref(tab:answerTypes) in the appendix shows the answer types in this study and their definitions and examples. Utterances that were not polar questions were simply coded as NA for this category. If children responded to polar questions with "yes" or "no", the category was YN and if they repeated with one of the coordinands the category was AB. If children said yes/no and followed it with one of the coordinands, the answer type was determined as YN (yes/no). For example, if a child was asked "Do you want orange juice or apple juice?" and the child responded with "yes, apple juice", our annotators coded the response as YN. The reason is that in almost all cases, if a simple yes/no response is felicitous, then it can also be optionally followed with mentioning a disjunct. However, if yes/no is not a felicitous response, then mentioning one of the alternatives is the only appropriate answer. For example, if someone asks "Do you want to stay here or go out?" a response such as "yes, go out" is infelicitous and a better response is to simply say "go out". Therefore, we counted responses with both yes/no and mentioning an alternative as a yes/no response.

### Inter-annotator Reliability

```{r agreement}
or_agreement <- read_csv("connective_learning/3_providence_annotations/reliability/agreement/or_agreement.csv")
and_agreement <- read_csv("connective_learning/3_providence_annotations/reliability/agreement/and_agreement.csv")
```

To train annotators and confirm their reliability for disjunction examples, two annotators coded the same 240 instances of disjunction. The inter-annotator reliability was calculated over 8 iterations of 30 examples each. After each iteration, annotators met to discuss disagreements and resolve them. They also decided whether the category definitions or annotation criteria needed to be made more precise. Training was completed after three consecutive iterations showed substantial agreement between the annotators for all categories (Cohen's $\kappa > 0.7$). Further details on inter-annotator reliability are presented in the appendix section.

### Results

First we look at how children responded to their parents' questions with *or* (Answer Type). Figure \@ref(fig:answerPlot) shows the monthly proportions of "yes/no" and alternative (AB) answers between the ages of 1 and 3 years. Initially, children provided no answer to questions, but by the age of 3 years, the majority of such questions received a yes/no (YN) or alternative (AB) answer. This increase in the proportion of responses to questions containing *or* between 20 to 30 months of age suggests that initial form-meaning mappings for disjunction may be formed in this age range.  

```{r answerPlot, fig.env="figure", fig.width=4, fig.height=2, fig.align="center", fig.cap="The proportions of children's answer types to polar questions containing the connective \\textit{or} at different ages (in months)."}
answer_prop <- 
  disjunctions %>%
  filter(answer!="N", answer!="S") %>%
  group_by(answer, age_months) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(age_months) %>%
  mutate(total = sum(counts), proportion = counts/total)

answer_prop %>%
  ggplot(aes(x= age_months, y=proportion, fill=answer)) + 
  geom_bar(stat = "identity", width=0.7) +
#  geom_linerange(aes(ymax = cih, ymin = cil)) + 
#  facet_grid(.~annotation) +
#  guides(fill=FALSE) +
#  scale_x_continuous(lim=c(13,39)) +
  scale_fill_manual(values=c("gray", "springgreen3", "springgreen4")) +
  labs(x="age (months)", y = "proportion")+
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```
<!--
These two answer types are not appropriate for all types of polar questions that contain *or*. For example, alternative answers are typically provided to alternative questions with the rise-fall intonation. For example, a question such as "do you want to stay here or go out?" receives an answer such as "stay-here/go-out" and not "yes/no". However, a polar disjunctive question such as "do you want any tea or coffee?" typically receives a "yes"/"no" rather than only one of the alternatives like "tea/coffee", even though both answers are possible. 

Based on such typical responses patterns, we can define appropriate answers to questions with disjunction in the following way: an alternative (AB) answer is appropriate for an alternative questions (with "or" and rise-fall intonation) and a "yes/no" answer (YN) is appropriate for a polar question. Of course this classification is too strict and misses some nuanced cases but it provides a rough estimate of appropriate answers offered to parents' questions. Figure \@ref(fig:answerHitsPlot) shows the monthly proportion of children's appropriate answers between the ages of 1 and 3. The results show that even with a strict measure, children show an increase in the proportion of their appropriate responses to questions containing *or* between 20 to 30 months of age (roughly 2 and 3 years of age). This increase in appropriate responses is consistent with the results from comprehension studies that suggest children's understanding of *and* and *or* develops between 2 and 4 years of age.  

```{r answerHitsPlot, fig.env="figure", fig.width=4, fig.height=2, fig.align="center", fig.cap="Proportion of children's appropriate resonses" }
disjunctions$appropriate <- "0"

disjunctions$appropriate[disjunctions$answer == "YN" & 
                                        disjunctions$utterance_type == "interrogative" &
                                        disjunctions$intonation == "rise"
                                       ] <- "1"

# In case you would like to count an alternative answer to a rising question as correct as well. The results are similar
#disjunctions$appropriate[disjunctions$answer == "AB" & 
#                                        disjunctions$utterance_type == "interrogative" &
#                                        disjunctions$intonation == "rise"
#                                       ] <- "1"

disjunctions$appropriate[disjunctions$answer == "AB" & 
                                        disjunctions$utterance_type == "interrogative" &
                                        disjunctions$intonation == "rise-fall"
                                       ] <- "1"

answer_prop <- 
  disjunctions %>%
  filter(answer!="N", answer!="S") %>%
  group_by(appropriate, age_months) %>%
  summarise(counts= n()) %>%
  group_by(age_months) %>%
  mutate(total = sum(counts), proportion = counts/total)

answer_prop %>%
  ggplot(aes(x= age_months, y=proportion, fill=appropriate)) + 
  geom_bar(stat = "identity", width=0.7) +
#  geom_linerange(aes(ymax = cih, ymin = cil)) + 
#  facet_grid(.~annotation) +
  scale_x_continuous(lim=c(12,38)) +
  #  guides(fill=FALSE) +
  scale_fill_manual(values=c("gray","navy")) +
  theme_few() +
  labs(x="age (months)", y = "proportion")+
  theme(text = element_text(size=11, family = "Times"))
```
-->
```{r interpretations}
interpretation_prop <- 
  connective_annotations %>%
  group_by(connective_meaning) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  mutate(total = sum(counts), est = counts/total)

connective_confint <-
  interpretation_prop$counts %>% 
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame()

interpretation_prop %<>% full_join(connective_confint, by="est")

#Order interpretation as AND > XOR > IOR > ...
interpretation_prop$connective_meaning %<>% fct_relevel("AND", "XOR")


#  connective_annotations %>%
#  group_by(connective_meaning, annotation) %>%
#  summarise(counts= n()) %>%
#    ggplot(aes(x=connective_meaning, y=counts)) +
#    geom_bar(stat="identity", width=0.2) +
#    facet_grid(.~annotation) + 
#    theme_few()
```

Next we consider the interpretations that *and* and *or* received in child-directed speech. The most common interpretation was the conjunctive interpretation (AND, `r round(interpretation_prop$est[1],2)*100`%) followed by the exclusive interpretation (XOR, `r round(interpretation_prop$est[6],2)*100`%). Figure \@ref(fig:connectivePlot) shows the distribution of connective interpretations by the connective words *and* and *or*^[All the confidence intervals shown in the plots for this section are simultaneous multinomial confidence intervals computed using the @sison1995simultaneous method.]. For *and*, the most frequent interpretation (in fact almost the only interpretation), was conjunction AND. For *or*, the most frequent interpretation was exclusive disjunction XOR. These results replicated the findings of @morris2008logically.

```{r interpretationPlot, include=F, fig.env="figure", fig.align="center", fig.width=3, fig.height=2.5, fig.cap="The proportion of different interpretations of the connectives \\textit{and/or} in child-directed speech"}
interpretation_prop %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  guides(fill=FALSE) +
  labs(x="", y="Proportion") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

```{r connectivePlot, fig.align="center", fig.env="figure", fig.width=5, fig.height=2.5, fig.cap="Interpretations of \\textit{and/or} in child-directed speech"}
connective_prop <- 
  connective_annotations %>%
  group_by(connective_meaning, annotation) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(annotation) %>%
  mutate(total = sum(counts), est = counts/total)

# calculating the multinomial confidence intervals
connective_confint_AND <-
  connective_prop %>%
  filter(annotation =="AND")
connective_confint_AND <-
  connective_confint_AND$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(connective_confint_AND, by="est")
connective_confint_OR <-
  connective_prop %>%
  filter(annotation =="OR")
connective_confint_OR <-
  connective_confint_OR$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(connective_confint_OR, by="est")

connective_prop <-
  bind_rows(connective_confint_AND, connective_confint_OR)

connective_prop %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_grid(.~annotation) +
  guides(fill=FALSE) +
  labs(y="Proportion", x="") +
  theme_few() +
  theme(text = element_text(size=11, family = "Times"))
```

Morris argued that given the high frequency of conjunction and exclusive disjunction in the input, children should initially (between the ages of 2 and 5 years) map the meanings of *and* and *or* as conjunction and exclusive disjunction. According to @morris2008logically, children learn the inclusive interpretation of disjunction later as they encounter more inclusive (logical) uses of *or*. However, comprehension tasks show that children between 3 and 5 tend to interpret *or* as inclusive disjunction rather than exclusive disjunction in a variety of declarative sentences [@chierchia2001acquisition; @notley2012children; @gualmini2000; @gualmini2000inclusion, among others]. How can children learn the inclusive semantics of *or* if they rarely hear it? This is the puzzle of learning disjunction, discussed in the introduction. The remainder of this section focuses on disjunction, and shows how different cues separate inclusive vs. exclusive interpretations, which in principle can help a learner in acquiring both the inclusive and exclusive interpretations of disjunction relatively quickly.

```{r utteranceTypes}
utteranceType_prop <- 
  disjunctions %>%
  filter(utterance_type == "declarative" | utterance_type == "imperative" | utterance_type == "interrogative") %>%
  group_by(connective_meaning, utterance_type, annotation) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(utterance_type, annotation) %>%
  mutate(total = sum(counts), est = counts/total)

#confidence intervals
utteranceType_confint_dec <-
  utteranceType_prop %>%
  filter(utterance_type =="declarative")
utteranceType_confint_dec <-
  utteranceType_confint_dec$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(utteranceType_confint_dec, by="est")

utteranceType_confint_int <-
  utteranceType_prop %>%
  filter(utterance_type =="interrogative")
utteranceType_confint_int <-
  utteranceType_confint_int$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(utteranceType_confint_int, by="est")

utteranceType_confint_imp <-
  utteranceType_prop %>%
  filter(utterance_type =="imperative")
utteranceType_confint_imp <-
  utteranceType_confint_imp$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(utteranceType_confint_imp, by="est") %>% unique()

utteranceType_confints <-
  bind_rows(utteranceType_confint_dec, utteranceType_confint_int, utteranceType_confint_imp)
```

```{r utterancetypePlot, fig.env="figure", fig.align="center", fig.width=4,fig.height=2.5, fig.cap="Connective interpretations in different sentence types."}
utteranceType_confints %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + geom_bar(stat = "identity", width=0.7) +
  facet_grid(.~utterance_type) +
  geom_linerange(aes(ymin=lwr.ci,ymax=upr.ci)) +
  guides(fill=FALSE) +
  labs(x="", y="proportion") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

Figure \@ref(fig:utterancetypePlot) shows the distribution of connective interpretations in declarative, interrogative, and imperative sentences. Interrogatives select for exclusive and inclusive interpretations, but overall they are more likely to be interpreted as exclusive (XOR). Imperatives are more likely to be interpreted as inclusive (IOR) or exclusive (XOR), and declaratives are most likely exclusive (XOR) or conjunctive (AND). It is important to note here that the inclusive interpretations of imperatives are largely due to invitations to action such as "Have some food or drink!". Such invitational imperatives seem to convey inclusivity (IOR) systematically. They are often used to give the addressee full permission with respect to both alternatives and it seems quite odd to use them to imply exclusivity (e.g. "Have some food or drink but not both!"), and they do not seem to be conjunctive either (e.g. "Have some food and have some drink!"). They rather imply that the addressee is invited to have food, drink, or both.

```{r intonation}
intonation_prop <- 
  disjunctions %>%
  group_by(connective_meaning, intonation) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(intonation) %>%
  mutate(total = sum(counts), est = counts/total)

#confidence intervals
intonation_confint_flat <-
  intonation_prop %>%
  filter(intonation =="flat")
intonation_confint_flat <-
  intonation_confint_flat$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(intonation_confint_flat, by="est")

intonation_confint_risefall <-
  intonation_prop %>%
  filter(intonation =="rise-fall")
intonation_confint_risefall <-
  intonation_confint_risefall$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(intonation_confint_risefall, by="est")

intonation_confint_rise <-
  intonation_prop %>%
  filter(intonation =="rise")
intonation_confint_rise <-
  intonation_confint_rise$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(intonation_confint_rise, by="est")

intonation_confints <-
  bind_rows(intonation_confint_flat, intonation_confint_risefall, intonation_confint_rise)
```

```{r intonationPlot, fig.env="figure", fig.align="center", fig.width=4, fig.height=2.5, fig.cap="The distribution of connective interpretations in flat, rising, and rise-fall intonation."}
intonation_confints %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_grid(.~intonation) +
  guides(fill=FALSE) +
  labs(x="", y="") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

While interrogatives select for exclusive and inclusive interpretations, the intonation on interrogatives can distinguish between these two readings. Figure \@ref(fig:intonationPlot) shows the proportions of different connective interpretations in the three intonation contours: flat, rise, and rise-fall. The rise and rise-fall contours are typical of interrogatives. The results show that, a disjunction with a rise-fall intonation is most likely interpreted as exclusive (XOR). If the intonation is rising, a disjunction is most likely inclusive (IOR). Finally, a disjunction with a flat intonation may be interpreted as exclusive (XOR), conjunctive (AND), or inclusive (IOR). These results are consistent with @pruitt2013interpretation's experimental findings that a rise-fall intonation contour on a disjunction results in an exclusive interpretation.

```{r consistency}
consistency_prop <- 
  disjunctions %>%
  group_by(connective_meaning, consistency,annotation) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(consistency,annotation) %>%
  mutate(total = sum(counts), est = counts/total)

#confidence intervals
consistency_confint_con <-
  consistency_prop %>%
  filter(consistency =="consistent")
consistency_confint_con <-
  consistency_confint_con$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistency_confint_con, by="est")

consistency_confint_inc <-
  consistency_prop %>%
  filter(consistency =="inconsistent")
consistency_confint_inc <-
  consistency_confint_inc$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistency_confint_inc, by="est") %>% unique()

consistency_confint <-
  bind_rows(consistency_confint_con, consistency_confint_inc)
```

```{r consistencyPlot, fig.env="figure", fig.width=4, fig.height=2.5, fig.align="center", fig.cap="Connective interpretations in disjunctions with consistent and inconsistent disjuncts."}
consistency_confint %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_grid(.~consistency) +
  guides(fill=FALSE) +
  labs(x="", y="proportion")+
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

Figure \@ref(fig:consistencyPlot) shows the proportions of connective interpretations in disjunctions with consistent vs. inconsistent disjuncts. When the disjuncts were consistent, the interpretation could be exclusive (XOR), inclusive (IOR), or conjunctive (AND). When the disjuncts were inconsistent, a disjunction almost always received an exclusive interpretation. These results suggest that the exclusive interpretation of a disjunction often stems from the inconsistent or contradictory nature of the disjuncts themselves.[^It should be noted here that in all *and*-examples, the disjuncts were consistent. This is not surprising given that inconsistent meanings with *and* result in a contradiction. The only exception to this was one example where the mother was mentioning two words as antonyms: "short and tall". This example is quite different from the normal utterances given that it is meta-linguistic and list words rather than asserting the content of the words.] In Figure \@ref(fig:consistencyByintonationPlot), we break down interpretations by both intonation and consistency. The results show a clear pattern: disjunctions are interpreted as exclusive XOR when they carry either inconsistent disjuncts or a rise-fall intonation. If the disjunction has consistent disjuncts and carries a rising intonation, it is most likely interpreted as inclusive IOR. This pattern suggests that using disjunct consistency and sentence intonation, a learner can reliably separate the exclusive and inclusive interpretations of disjunction. 

```{r consistencyByIntonation}
consistonation_prop <- 
  disjunctions %>%
  group_by(connective_meaning, consistency, intonation) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(intonation, consistency) %>%
  mutate(total = sum(counts), est = counts/total)

#confidence intervals
consistonation_confint_conflat <-
  consistonation_prop %>%
  filter(consistency =="consistent", intonation=="flat")
consistonation_confint_conflat <-
  consistonation_confint_conflat$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_conflat, by="est")

consistonation_confint_incflat <-
  consistonation_prop %>%
  filter(consistency =="inconsistent", intonation=="flat")
consistonation_confint_incflat <-
  consistonation_confint_incflat$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_incflat, by="est")

consistonation_confint_conrise <-
  consistonation_prop %>%
  filter(consistency =="consistent", intonation=="rise")
consistonation_confint_conrise <-
  consistonation_confint_conrise$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_conrise, by="est")

consistonation_confint_incrise <-
  consistonation_prop %>%
  filter(consistency =="inconsistent", intonation=="rise")
consistonation_confint_incrise <-
  consistonation_confint_incrise$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_incrise, by="est")

consistonation_confint_confall <-
  consistonation_prop %>%
  filter(consistency =="consistent", intonation=="rise-fall")
consistonation_confint_confall <-
  consistonation_confint_confall$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_confall, by="est")

consistonation_confint_incfall <-
  consistonation_prop %>%
  filter(consistency =="inconsistent", intonation=="rise-fall")
consistonation_confint_incfall <-
  consistonation_confint_incfall$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(consistonation_confint_incfall, by="est")

consistonation_confint <-
  bind_rows(consistonation_confint_conflat, consistonation_confint_incflat,
            consistonation_confint_conrise, consistonation_confint_incrise,
            consistonation_confint_confall, consistonation_confint_incfall)
```

```{r consistencyByintonationPlot, fig.env="figure", fig.align="center", fig.width=6, fig.height=3, fig.cap="Interpretations of and/or in the three intonation contours flat, rising, and rise-fall."}
consistonation_confint %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat="identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_grid(consistency~intonation, scales="free_y") +
  guides(fill=FALSE) +
  labs(x="", y="proportion") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

```{r syntax}
syntax_prop <- 
  disjunctions %>%
  group_by(connective_meaning, syn_level) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(syn_level) %>%
  mutate(total = sum(counts), est = counts/total)

#confidence intervals
syntax_confint_sen <-
  syntax_prop %>%
  filter(syn_level =="SEN")
syntax_confint_sen <-
  syntax_confint_sen$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(syntax_confint_sen, by="est")

syntax_confint_nom <-
  syntax_prop %>%
  filter(syn_level =="NOM")
syntax_confint_nom <-
  syntax_confint_nom$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(syntax_confint_nom, by="est")

syntax_confint <-
  bind_rows(syntax_confint_sen, syntax_confint_nom)
```

```{r syntaxPlot, fig.env="figure", fig.width=5, fig.height=2.5, fig.align="center", fig.cap="Connective interpretations in clausal and sub-clausal disjunctions."}
syntax_confint$syn_level <- fct_recode(syntax_confint$syn_level, clausal="SEN", `sub-clausal`="NOM")

syntax_confint %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width=0.7) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_grid(.~syn_level) +
  guides(fill=FALSE) +
  labs(x="", y="proportion") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

Figure \@ref(fig:syntaxPlot) shows connective interpretations by the syntactic level of the disjunction. The results suggest a small effect of clausal level disjuncts. Disjunctions were more likely to be interpreted as exclusive when their disjuncts were clauses or verbs rather than nominals, adjectives, or prepositions (all sub-clausal units).  

```{r speech_acts}
speechAct_prop <- 
  disjunctions %>%
  group_by(connective_meaning, speech_act) %>%
  summarise(counts= n()) %>%
  na.omit() %>%
  group_by(speech_act) %>%
  mutate(total = sum(counts), est = counts/total)

# calculating the multinomial confidence intervals
descriptions_confint <-
  speechAct_prop %>%
  filter(speech_act =="description")
descriptions_confint <-
  descriptions_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(descriptions_confint, by="est")

clarifications_confint <-
  speechAct_prop %>%
  filter(speech_act =="clarification")
clarifications_confint <-
  clarifications_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(clarifications_confint, by="est")

conditional_confint <-
  speechAct_prop %>%
  filter(speech_act =="conditional")
conditional_confint <-
  conditional_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(conditional_confint, by="est")

defex_confint <-
  speechAct_prop %>%
  filter(speech_act =="defex")
defex_confint <-
  defex_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(defex_confint, by="est")

directive_confint <-
  speechAct_prop %>%
  filter(speech_act =="directive")
directive_confint <-
  directive_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(directive_confint, by="est")

identification_confint <-
  speechAct_prop %>%
  filter(speech_act =="identification")
identification_confint <-
  identification_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(identification_confint, by="est")

options_confint <-
  speechAct_prop %>%
  filter(speech_act =="options")
options_confint <-
  options_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(options_confint, by="est")

preference_confint <-
  speechAct_prop %>%
  filter(speech_act =="preference")
preference_confint <-
  preference_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(preference_confint, by="est") %>% unique()

repair_confint <-
  speechAct_prop %>%
  filter(speech_act =="repair")
repair_confint <-
  repair_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(repair_confint, by="est")

unconditional_confint <-
  speechAct_prop %>%
  filter(speech_act =="unconditional")
unconditional_confint <-
  unconditional_confint$counts %>%
  MultinomCI(conf.level = 0.95, method = "sisonglaz") %>% data.frame() %>%
  full_join(unconditional_confint, by="est")

speechActs <- bind_rows(descriptions_confint, options_confint, unconditional_confint, repair_confint, preference_confint, identification_confint, directive_confint, defex_confint, conditional_confint, clarifications_confint)

speechActs$speech_act <- fct_relevel(speechActs$speech_act, "preference", "description", "clarification", "identification", "conditional", "directive", "options", "repair", "defex", "unconditional")
```

```{r speechActPlot, fig.env="figure", fig.align="center", fig.width=6, fig.height=5, fig.cap="Connective interpretations in different communicative functions."}
speechActs %>%
  ggplot(aes(x= connective_meaning, y=est, fill=connective_meaning)) + 
  geom_bar(stat = "identity", width = 0.5) +
  geom_linerange(aes(ymax = upr.ci, ymin = lwr.ci)) + 
  facet_wrap(~speech_act) +
  guides(fill=FALSE) +
  labs(x="", y="proportions") +
  theme_few() +
  theme(text = element_text(size=10, family = "Times"))
```

Figure \@ref(fig:speechActPlot) shows the proportions of connective interpretations in the 10 different communicative functions of this study. The results show that certain functions increase the likelihood of some connective interpretations. An exclusive (XOR) interpretation of *or* is common in acts of clarification, identification, stating/asking preferences, stating/asking about a description, or making a conditional statements. These results are consistent with expectations on the communicative intentions of that these utterances carry. In clarifications, the speaker needs to know which of two alternatives the other party meant. Similarly in identifications, speaker needs to know which category does a referent belongs to. In preferences, parents seek to know which of two alternatives the child wants. Even though descriptions could be either inclusive or exclusive, in the current sample, most descriptions were questions about the state of affairs and required the child to provide one of the alternatives as the answer. In conditionals such as "come here or you are grounded", the point of the threat is that only one disjunct can be true: either "you come and you are not grounded" or "you don't come and you are grounded". This is similar to an exclusive interpretation of *or*.  


Repairs often received an exclusive (XOR) or a second-disjunct-true (NAB) interpretation. This is expected given that in repairs the speaker intends to say that the first disjunct is incorrect or inaccurate. Unconditionals and definitions/examples always had a conjunctive (AND) interpretation. Again, this is to be expected. In such cases the speaker intends to communicate that all options apply. If the mother says that "cats are animals like lions or tigers", she intends to say that both lions and tigers are cats and not one or the other. Interestingly, in some cases (not all), *or* is replaceable by *and*: "cats are animals like lions and tigers". In unconditionals, the speaker communicates that in both alternatives, a certain proposition holds. For example, if the mother says "ready or not, here I come!", she communicates that "I come" is true in both cases where "you are ready" and "you are not ready".  

Options were often interpreted either as conjunctive (AND) or inclusive (IOR). The category "options" contained examples of free-choice inferences such as "you could drink orange juice or apple juice". This study found free-choice examples much more common than the current literature on the acquisition of disjunction suggests. Finally, directives received either an IOR or XOR interpretation. It is important to note here that the most common communicative function in the data were preferences and descriptions. Other communicative functions such as unconditionals or options were fairly rare. Despite their infrequent appearance, these constructions must be learned by children at some point, since almost all adults know how to interpret them. It is clear from the investigation here that any learning account for function word meaning/interpretation also needs to account for how such infrequent constructions are learned.  
```{r eval=FALSE}

disjunctions$connective_meaning <- relevel(disjunctions$connective_meaning, ref = "NAB")

library(brms)
or_model <- brm(connective_meaning ~ speech_act + consistency + utterance_type + intonation + syn_level + (1|id), family=categorical,  control = list(adapt_delta = 0.9), prior=c(set_prior ("normal (0, 10)")), data=disjunctions)

summary(or_model)
coef (or_model)

or_model2 <- brm(connective_meaning ~ speech_act*consistency*utterance_type*intonation*syn_level + (1|id), control = list(adapt_delta = 0.9), prior=c(set_prior ("normal (0, 10)")), family=categorical,  data=disjunctions)

summary(or_model2)
```

### Discussion

The goal of this study was to discover the potential cues in child-directed speech that could help children learn the interpretations of *and* and *or*. The study presented 1000 examples of *and* and *or* in child-directed speech, annotated for their truth-conditional interpretation, as well as five candidate cues to their interpretation: (1) Utterance Type; (2) Intonation Type; (3) Syntactic Level; (4) Conceptual Consistency; (5) Communicative Function. Like @morris2008logically, this study found that the most common interpretations of *and* and *or* are conjunction AND and exclusive disjunction XOR. When the data were broken down by the connectives, *and* was almost always interpreted as a conjunction while *or* received three main interpretations: exclusive disjunction XOR, inclusive disjunction IOR, and conjunction AND. 

While the most frequent interpretation of *or* was exclusive XOR overall followed by IOR, the distribution of disjunction interpretations shifted when they were broken down by the cues identified here. A disjunction was most likely exclusive if the alternatives were inconsistent (i.e. contradictory). A disjunction was most likely exclusive if it appeared in a question. Within questions, a disjunction was most likely exclusive if the intonation was rise-fall. If the intonation was rising, the question was interpreted as inclusive. The syntactic category of the disjuncts could also provide information for interpretation. If the disjuncts were clausal then it was more likely for the disjunction to be interpreted as exclusive, even though this effect was small. Finally, specific communicative functions required specific interpretations of the connective. *Or* often received a conjunctive interpretation in the following contexts: defining terms and providing examples, enumerating options, and in unconditional constructions. These results suggest that in order to successfully learn to interpret a disjunction, children need to pay attention to a wide variety of formal and conceptual factors.

In order to have a rough measure of children's comprehension of disjunction, this study also investigated the types of answers they provided to polar questions with disjunction. Between the ages of 20 and 30 months (roughly 1;6 to 2;6 years), children start to answer *or* questions appropriately. They would respond to a yes/no question such as "do you want any apple juice or orange juice?" with a yes/no answer. They would also respond to an alternative question, as in"do you want to play inside or outside?", with one of the alternates, e.g. "inside". This finding is consistent with the first corpus study presented in this chapter, which reported that the age range between 1;6 and 4 is the age range in which children develop their understanding of *and* and *or*.

Due to the exploratory nature of this study, it is important to replicate and extend these results and conclusions in future studies. For example, future studies could use an automated procedure for the annotation of categories such as utterance type, syntactic level, and intonation. An automated procedure would also allow for the annotation of larger samples and so could result in more reliable estimates for the role of various factors in learning the meanings of function words. For categories such as communicative function and connective interpretation, future studies could use a larger number of independent annotators to increase the speed and number of annotations. However, several results reported in this study are independently supported by previous research. @morris2008logically found similar results with respect to the overall interpretation of disjunction in child-directed speech: *and* is most often interpreted as conjunction and *or* as exclusive disjunction. In an experimental study, @pruitt2013interpretation have shown that a rise-fall intonation results in an exclusive interpretation. @geurts2006exclusive has argued that a portion of exclusivity inferences are simply due to the fact that the alternatives are mutually exclusive and inconsistent. 

Finally, the list of cues investigated here is in no way exhaustive. There are at least two additional, possibly important factors/cues that I set aside due to the difficulties that their annotation would have introduced. First, an exclusive interpretation is sometimes the result of a presupposition that only one alternative can hold or would matter for the purposes of the conversation. For example, in the context of a class activity where students pair up, a statement such as "Lisa worked with Ann or John" is interpreted as exclusive simply because the context already presupposes that only one disjunct can be true. Second, some exclusivity inferences are due to the speaker's choice of connective, namely using *or* rather than *and*. @grice1989studies famously argued that in some cases, we interpret a disjunction like *A or B* as A or B, but not both because we reason that if the speaker intended to communicate that both alternatives hold, s/he would have said *A and B*. This study did not annotate for such cases. However, the study's results suggest that such cases of exclusive interpretations are less frequent in child-directed speech that the ones already annotated for. Investigating how often such cases of pragmatic exclusion appear in child-directed speech can help us better understand the role of input in children's acquisition of scalar implicatures.

# Learning to interpret a disjunction

Given the wide range of interpretations that *or* can have, how can children learn to interpret it correctly? This is what study 3 addresses. In doing so, it also provides a solution to the puzzle of learning disjunction. To remind you about the puzzle, previous research have shown that the majority of *or*-examples children hear are exclusive. However, comprehension studies report that between the ages of three and five, children can interpret *or* as inclusive disjunction in declarative sentences [@crain2012emergence]. The finding of the comprehension studies and the corpus studies taken together present a learning puzzle: how can children learn to interpret *or* as inclusive if they mostly hear exclusive examples? This chapter provides a solution by developing a cue-based account for children's acquisition of connectives. More generally, the account proposed in this chapter is helpful for learning words with multiple interpretations when one interpretation dominates the learner's input. 
<!--
Learning from multiple cues is a common approach in language acquisition [see @monaghan2014multiple, for an overview]. In the domain of function word semantics, @bloom1997linguistic proposed a cue-based account for the acquisition of number words.
-->
## Cues to coordinator meanings

```{r data_prep, echo=FALSE, warning=FALSE, message=FALSE}
alex_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-alex.csv", nrows=100)
lily_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-lily.csv", nrows=99)
vio_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-vio.csv", nrows=102)
will_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-will.csv", nrows=100)
naima_data <- read.csv("connective_modeling/annotation_data/ProvidenceOR-Naima.csv", nrows=241)

naima_data <- 
  naima_data %>%
  filter(!is.na(exclusivity), !is.na(intonation))

all_data <- rbind(alex_data, lily_data, vio_data, will_data, naima_data)

all_data$intonation <- as.factor(all_data$intonation)

all_data$exclusion <- fct_recode(all_data$exclusion, "Consistent" = "ELS", "Inconsistent" = "EXC")
all_data$intonation <- fct_recode(all_data$intonation, "Flat" = "0", "Rising" = "1", "Rise-Fall" = "2")
all_data$intonation <- fct_recode(all_data$intonation, "Flat" = "0", "Rising" = "1", "Rise-Fall" = "2")
```

```{r data_wrangling, echo=FALSE, warning=FALSE, message=FALSE}
raw_data <- 
  all_data %>%
  group_by(id, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX) %>%
  gather(EXIN, counts, EX:IN) %>%
  mutate(prop = counts / total) %>%
  group_by(EXIN) %>%
  summarize(cih = ci.high(prop),
            cil = ci.low(prop),
            prop = mean(prop))

graph_data <- 
  all_data %>%
  group_by(id, intonation, exclusion, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = EX + IN) %>%
  gather(exclusivity, counts, EX:IN) %>%
  mutate(prop = counts / total) %>%
  group_by(exclusivity, intonation, exclusion) %>%
  summarize(cih = ci.high(prop),
            cil = ci.low(prop),
            prop = mean(prop)) 

counts_table<-  
  all_data %>%
  group_by(intonation, exclusion, syn_level, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX)

exclusivity_overall <-
  all_data %>%
  group_by(exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX) %>%
  gather(exclusivity, counts, EX:IN) %>%
  mutate(prop = counts / total)

cds_disjunction_model <- summary(glmer(exclusivity ~ intonation + exclusion + (1|id), family="binomial", data=all_data))
```

```{r importSyntaxInfo}
annotations <- read_csv("connective_learning/3_providence_annotations/providence_merged.csv")

synTable <-
annotations %>%
  group_by(syn_level) %>%
  summarize(counts=n(), total = nrow(annotations), prop = counts/total)
```

Three important compositional cues can help learners in restricting their hypotheses to coordinator meanings. First, as pointed out by @haspelmath2007, coordination has specific compositional properties. Coordinators combine two or more units of the same type and return a larger unit of the same type. The larger unit has the same semantic relation with the surrounding words as the smaller units would have had without coordination. These properties separate coordinators from other function words such as articles, quantifiers, numerals, prepositions, and auxiliaries which are not used to connect sentences or any two similar units for that matter. In fact, the special syntactic properties of coordinators have compelled syntactic theories to consider specific rules for coordination.  

The literature on syntactic bootstrapping suggests that children can use syntactic properties of the input to limit their word meaning hypotheses to the relevant domain [@brown1957linguistic; @gleitman1990structural; see @fisher2010syntactic for a review]. In the current `r nrow(annotations)` annotations of conjunction and disjunction, I found that *and* and *or* connected sentences/clauses `r round(synTable$prop[2]*100)`% of the time. This pattern is unexpected for any other class of function words and it is possible that the syntactic distribution of coordinators cue the learners to the space of sentential connective meanings. 

Second, in the annotation study I found that *and* never occurs with inconsistent coordinands (e.g. "clean and dirty") while *or* commonly does (e.g. "clean or dirty"). The inconsistency of the coordinands can cue the learner to not consider conjunction as a meaning for the coordinator given that a conjunctive meaning would too often lead to a contradiction at the utterance level. On the other hand, choosing disjunction as the meaning avoids this problem. Third, the large scale study of Chapter \@ref(corpus) found that *or* is more likely to occur in questions than statements while *and* is more likely in statements. Since questions often contain more uncertainty while statements are more informative, it is possible that these environments bias the learner towards selecting hypotheses that match this general communicative function. Disjunction is less informative than conjunction and it is possible that the frequent appearance of *or* in questions cues learners to both its meaning as a disjunction as well as the ignorance inference commonly associated with it.

Finally, it is reasonable to assume that not all binary connective meanings shown in Figure \@ref(fig:binaryLogicalConnectivess) are as likely for mapping. For example, coordinators that communicate tautologies or contradictions seem to be not good candidates for informative communication. Similarly, if A coordinated with B simply asserts the truth of A and says nothing about B, it is unclear why it would be needed if the language already has the means of simply asserting A. It is possible that pragmatic principles already bias the hypothesis space to favor candidates that are communicatively more efficient.

```{r binaryLogicalConnectivess, fig.env="figure", fig.align="center", fig.width=5, fig.height=2, fig.cap="The truth table for the 16 binary logical connectives. The rows represent the set of situations where zero, one, or both propositions are true. The columns represent the 16 possible connectives and their truth conditions. Green cells represent true situations."}
binary_connectives<- png::readPNG("figs/binary_connective.png")
grid::grid.raster(binary_connectives)
```

Even though these findings are suggestive, they need to be backed up by further observational and experimental evidence to show that children do actually use these cues in learning connective meanings. In the next section, I turn to the more specific issue of learning the correct interpretation of *and* and *or* from the input data. As in the case of number words, previous research has provided insight into how children comprehend a disjunction and what they hear from their parents. The main question is how children learn what they comprehend from what they hear. I turn to this issue in the next section.

## Learning to interpret *and* and *or*: A cue-based account {#myaccount}

Previous comprehension studies have shown that children as early as age three can interpret a disjunction as inclusive [see @crain2012emergence for an overview]. However, @morris2008logically showed that exclusive interpretations are much more common than other interpretations of disjunction in children's input. In Figure \@ref(fig:interpretation), I show the results of Chapter \@ref(corpus)'s annotation study by grouping the disjunction interpretations into exclusive (EX) and inclusive (IN), i.e. non-exclusive categories. These results replicate Morris' [-@morris2008logically] finding and reinforce a puzzle raised by @crain2012emergence: How can children learn the inclusive interpretation of disjunction when the majority of the examples they hear are exclusive? To answer this question, I draw on insights from the Gricean approach to semantics and pragmatics discussed in Chapter \@ref(sempragLit). 

```{r interpretation, fig.env='figure',fig.width=1.8, fig.height=1.8, fig.align="center",fig.cap = "Proportion of exclusive and inclusive interpretations of disjunction in child-directed speech. Error bars represent bootstrapped 95\\% confidence intervals."}
ggplot(raw_data, aes(x= EXIN, y=prop, fill=EXIN)) + 
  theme_few(base_size = 10) + 
  geom_col(width=0.7) +
  geom_linerange(aes(ymax = cih, ymin = cil)) + 
  guides(fill=FALSE) +
  labs(title = "", x = "", y = "Proportion") + 
  theme(text = element_text(family = "Times"))+
  scale_colour_solarized()
```

Research in Gricean semantics and pragmatics has shown that the word *or* is not the only factor relevant to the interpretation of a disjunction. It is not only the presence of the word *or* that leads us to interpret a disjunction as inclusive, exclusive, or conjunctive, but rather the presence of *or* along with several other factors such as intonation [@pruitt2013interpretation], the meaning of the disjuncts [@geurts2006exclusive], and the conversational principles governing communication [@grice1989studies]. The interpretation and acquisition of the word *or* cannot, therefore, be separated from all the factors that accompany it and shape its final interpretation. 

In the literature on word learning and semantic acquisition, form-meaning mapping is often construed as mapping an isolated form such as *gavagai* to an isolated concept such as "rabbit". While this approach may be feasible for content words, it will not work for function words such as *or*. First, the word *or* cannot be mapped in isolation from its formal context. As @pruitt2013interpretation showed, the intonation that accompanies a disjunction affects its interpretation. Therefore, a learner needs to pay attention to the word *or* as well as the intonation contour that accompanies it. Second, the word *or* cannot be mapped to its meaning isolated from the semantics of the disjuncts that accompany it. As @geurts2006exclusive argued, the exclusive interpretation is often enforced simply because the options are incompatible. For example, "to be or not to be" is exclusive simply because one cannot both be and not be. In addition, conversational factors play an important role in the interpretation of *or* as @grice1989studies argued. In sum, the interpretation and acquisition of function words such as *or* require the learner to consider the linguistic and nonlinguistic context of the word and map the meanings accordingly.

Previous accounts have adopted a model in which a function word such as *or* is mapped directly to its most likely interpretation: 

*or* $\rightarrow \oplus$

This model is often used in cross-situational accounts of content words. Here I argue that the direct mapping of *or* to its interpretation without consideration of its linguistic context is the primary cause of the learning puzzle for *or*. Instead, I propose that the word *or* is mapped to an interpretation in a context-dependent manner, along with the interpretive cues that accompany it such as intonation and disjunct semantics: 

[connective: *or*, Intonation: rise-fall, Disjuncts: inconsistent] $\rightarrow \oplus$

[connective: *or*, Intonation: rising, Disjuncts: consistent] $\rightarrow \lor$

Figure \@ref(fig:interpretationByIntonationAndConsistency) shows that the rate of exclusive interpretations change systematically when the data are broken down by intonation and consistency. Given a rise-fall intonation contour, a disjunction is almost always interpreted as exclusive. Similarly, if the propositions are inconsistent, the disjunction is most likely interpreted as exclusive. When either of these two features are absent, a disjunction is more likely to receive an inclusive interpretation.

```{r interpretationByIntonationAndConsistency, fig.env='figure', fig.width=3.5, fig.height=2.5, fig.align="center", fig.cap = "Exclusive and inclusive interpretations broken down by intonation (flat, rise, rise-fall) and consistency. Error bars represent bootstrapped 95\\% confidence intervals."}
ggplot(graph_data, aes(x= exclusivity, y=prop, fill=exclusivity)) + 
  geom_col(width=0.7) +
  geom_linerange(aes(ymax = cih, ymin = cil)) +
  guides(fill=FALSE) +
  theme_few(base_size = 10) + 
  labs(title = "", x = "", y = "Proportion") + 
  scale_colour_solarized() + facet_grid(exclusion~intonation) + theme(text = element_text(family = "Times"))
```

In this account, it is not a single word that gets mapped to an interpretation but rather a cluster of features. This method has two advantages. First, it deals with the context dependency of disjunction interpretation. The learner knows that *or* with some intonation has to be interpreted differently from one with another. Second, it allows the learner to pull apart the contribution of *or* from the interpretive cues that often accompany it. In fact, analysis of all mapping clusters in which *or* participates and generalization over them can help the learner extract the semantics of *or* the way it is intended by Gricean accounts of semantics/pragmatics. For those skeptical of such an underlying semantics for *or*, there is no need for further analysis of the mapping clusters. The meaning of *or* as a single lexical item is distributed among the many mappings in which it participates. In the next section, I implement this idea using decision tree learning.

## Modeling Using Decision Tree Learning {#DecisionTrees}

A decision tree is a classification model structured as a hierarchical tree with nodes, branches, and leaves [@breiman2017classification]. The tree starts with an initial node, called the root, and branches into more nodes until it reaches the leaves. Each node represents the test on a feature, each branch represents an outcome of the test, and each leaf represents a classification label. Using a decision tree, observations can be classified or labeled based on a set of features. 

*I personally wouldn't include this example in a paper, unnecessary?*
For example, we can make a decision tree to predict whether a food item is a fruit or not based on its color (green or not) and shape (round or not). An example decision tree is the following: at the root, the model can ask whether the item is green or not. If yes, the model creates a leaf and labels the item as "not fruit". If not, the model creates another node and asks if the item is round. If yes, the item is classified as a "fruit" and if not it is classified as "not fruit". 

Decision trees have several advantages for modeling cue-based accounts of semantic acquisition. First, decision trees use a set of features to predict the classification of observations. This is analogous to using cues to predict the correct interpretation of a word or an utterance. Second, unlike many other machine learning techniques, decision trees result in models that are interpretable. Third, the order of decisions or features used for classification is determined based on information gain. Features that appear higher (earlier) in the tree are more informative and helpful for classification. Therefore, decision trees can help us understand which cues are probably more helpful for the acquisition and interpretation of a word.

Decision tree learning is the construction of a decision tree from labeled training data. This section applies decision tree learning to the annotated data of Chapter \@ref(corpus) by constructing random forests [@ho1995random; @breiman2001random]. In random forest classification, multiple decision trees are constructed on subsets of the data, and each tree predicts a classification. The ultimate outcome is a majority vote of each trees classification. Since decision trees tend to overfit data, random forests control for overfitting by building more trees and averaging their results. **(Citation)** Next section discusses the methods used in constrcting the random forests for interpreting connectives *or*/*and*.

### Methods

The random forest models were constructed using python's Sci-kit Learn package [@pedregosa2011scikit]. The annotated data had a feature array and a connective interpretation label for each connective use. Connective interpretations included exclusive (XOR), inclusive (IOR), conjunctive (AND), negative inclusive (NOR), and NPQ which states that only the second proposition is true. The features or cues used included all other annotation categories: intonation, consistency, syntactic level, utterance type, and communicative function. All models were trained with stratified 10-Fold cross-validation to reduce overfitting. Stratified cross-validation maintains the distribution of the initial data in the random sampling to build cross validated models. Maintaining the data distribution ensures a more realistic learning environment for the forests. Tree success was measured with F1-Score, harmonic average of precision and recall **(Citation)**.

First a grid search was run on the hyperparamter space to establish the number of trees in each forest and the maximum tree depth allowable. The grid search creates a grid of all combinations of forest size and tree depth and then trains each forest from this grid on the data. The forests with the best F1-score and lowest size/depth are reported. **(Citation*)**  The default number of trees for the forests was set to 20, with a max depth of eight and a minimum impurity decrease of 0. Impurity was measured with gini impurity, which states the odds that a random member of the subset would be mislabled if it were randomly labeled according to the distribution of labels in the subset. **(Citation)**

Decision trees were fit with high and low minimum gini decrease values. High minimum gini decrease results in a tree that does not use any features for branching. Such a tree represents the baseline or traditional approach to mapping that directly maps a word to its most likely interpretation. Low minimum gini decrease allows for a less conservative tree that uses multiple cues/features to predict the interpretation of a disjunction. Such a tree represents the cue-based context-sensitive account of word learning discussed in the previous section. 

### Results

We first present the results of the random forests in the binary classification task. The models were trained to classify exclusive and inclusive interpretations of disjunction. For visualization of trees, we selected the highest performing tree in the forest by testing each tree and selecting for highest F1 score. While the forests performance is not identical to the highest performing tree, the best tree gives an illustrative example of how the tree performs. 

Figure \@ref(fig:binaryBaseline) shows the best performing decision tree with high minimum gini decrease. As expected, a learner that does not use any cues would interpret *or* as exclusive all the time. This is the baseline model. Figure \@ref(fig:binaryCueBased) shows the best performing decision tree with low minimum gini decrease. The tree has learned to use intonation and consistency to classify disjunctions as exclusive or inclusive. As expected, if the intonation is rise-fall or the disjuncts are inconsistent, the interpretation is exclusive. Otherwise, the disjunction is classified as inclusive. 

```{r binaryBaseline, fig.asp=0.4, fig.cap="Baseline tree grown with minimum impurity decrease of 0.2. The tree always classifies examples of disjunction as exclusive."}
binaryBaseline <- readJPEG("connective_modeling/exin_baselineTree.jpg")
grid::grid.raster(binaryBaseline)
```

```{r binaryCueBased, fig.cap="Cue-based tree grown with minimum impurity decrease of 0.01. The tree classifies examples of disjunction with rise-fall intonation as exclusive (intonation > 1.5). If the intonation is not rise-fall but the disjuncts are inconsistent (consistency < 0.5), then the disjunction is still classified as exclusive. However, if neither of these two hold, the disjunction is classified as inclusive."}
binaryCueBased <- readJPEG("connective_modeling/exin_cueBasedTree.jpg")
grid::grid.raster(binaryCueBased)
```

Figure \@ref(fig:XorBinary) shows the average F1 scores of the baseline and cue-based models in classifying exclusive examples. The models perform relatively well and similar to each other, but the cue-based model performs slightly better. The real difference between the baseline model and the cue-based model is in their performance on inclusive examples. Figure \@ref(fig:IorBinary) shows the F1 score of the forests as a function of the training size in classifying inclusive examples. As expected, the baseline model performs very poorly while the cue-based model does a relatively good job and improves with more examples.

```{r XorBinary, fig.cap="The average F1 score for class XOR (exclusive) as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XorBinary <- readPNG("connective_modeling/ex-exin.png")
grid::grid.raster(XorBinary)
```

```{r IorBinary, fig.cap="The average F1 score for class IOR (inclusive) as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IorBinary <- readPNG("connective_modeling/in-exin.png")
grid::grid.raster(IorBinary)
```

Next, we use decision tree learning in a ternary classification task. The model uses features to interpret a coordination with *and* and *or* as inclusive (IOR), exclusive (XOR), or conjunctive (AND). Figure \@ref(fig:ternaryBaseline) shows the baseline decision tree with high minimum gini decrease, which only uses the presence of the words *or*/*and* to interpret conjunction and disjunction. As expected, the tree interprets a coordination with *and* as a conjunction and one with *or* as exclusive disjunction. Figure \@ref(fig:ternaryCueBased) shows the cue-based decision tree with low minimum gini decrease. In addition to the presence of *and* and *or*, the tree uses intonation, consistency, communicative function, and utterance type to distinguish exclusive, inclusive, and conjunctive uses of disjunction. In short, a disjunction that is rise-fall, inconsistent, or has a conditional communicative function is classified as exclusive. Otherwise the disjunction is classified as inclusive. The tree also finds conjunctive interpretations of disjunction more likely in declarative sentences than interrogatives.

```{r ternaryBaseline, fig.asp=0.6, fig.cap="The baseline tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.2. The tree uses the words \\textit{and/or} and classifies them as conjunction and exclusive disjunction respectively."}
ternaryBaseline <- readPNG("connective_modeling/intermediate_baselineTree.png")
grid::grid.raster(ternaryBaseline)
```

```{r ternaryCueBased, fig.asp=2.5, fig.cap="The cue-based tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.01. After using the words \\textit{and/or}, the tree uses intonation, consistency, and the conditional communicative function to classify a large number of exclusive cases. Then it uses utterance type (interrogative) to label inclusive cases."}
ternaryCueBased <- readPNG("connective_modeling/intermediate_cueBasedTree.png")
grid::grid.raster(ternaryCueBased)
```

Figure \@ref(fig:ANDintermediate) shows the average F1 score of the conjunctive interpretations (AND) for the baseline and the cue-based models. Since the vast majority of the conjunctive interpretations are predicted by the presence of the word *and*, the baseline and cue-based models show similar performances. Setting aside conjunction examples, Figure \@ref(fig:ANDintermediateDis) shows the average F1 score of the AND interpretation of disjunction only. Here we see that the cue-based model performs better than the default model in guessing conjunctive interpretations of disjunction. The informal analysis of the trees suggest that the model does this by using the "speech act" cue. Figure \@ref(fig:XORintermediate) shows the average F1-score of the exclusive interpretations (XOR) for the baseline and the cue-based models. The cue-based model does slightly better than the baseline model. As before, the most important improvement comes in identifying inclusive examples. Figure \@ref(fig:IORintermediate) shows the average F1-score of the inclusive interpretations (IOR) for both baseline and cue-based models. The baseline model performs very poorly while the cue-based model is capable of classifying inclusive examples as well.

```{r ANDintermediate, fig.cap="The average F1 score for class AND as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
ANDintermediate <- readPNG("connective_modeling/and-intermediate.png")
grid::grid.raster(ANDintermediate)
```

```{r ANDintermediateDis, fig.cap="The average F1 score for class AND of disjunction examles as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
ANDintermediateDis <- readPNG("connective_modeling/and-intermediate-disjunction.png")
grid::grid.raster(ANDintermediateDis)
```

```{r XORintermediate, fig.cap="The average F1 score for class XOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XORintermediate <- readPNG("connective_modeling/xor-intermediate.png")
grid::grid.raster(XORintermediate)
```

```{r IORintermediate, fig.cap="The average F1 score for class IOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IORintermediate <- readPNG("connective_modeling/ior-intermediate.png")
grid::grid.raster(IORintermediate)
```

Finally, welook at decision trees trained on the annotation data to predict all the interpretation classes for disjunction: AND, XOR, IOR, NOR, and NPQ. Figure \@ref(fig:wholeBaseline) shows the baseline model that only uses the words *and* and *or* to classify. As expected, *and* receives a conjunctive interpretation (AND) and *or* receives an exclusive interpretation (XOR). Figure \@ref(fig:wholeCueBased) shows the best example tree of the cue-based model. The leaves of the tree show that it recognizes exclusive, inclusive, conjunctive, and even negative inclusive (NOR) interpretations of disjunction. How does the tree achieve that? Like the baseline model, the tree first asks about the connective used: *and* vs. *or*. Then like the previous models, it asks about intonation and consistency. If the intonation is rise-fall, or the disjuncts are inconsistent, the interpretation is exclusive. Then it asks whether the sentence is an interrogative or a declarative. If interrogative, it guesses an inclusive interpretation. This basically covers questions with a rising intonation. Then the tree picks declarative examples that have conditional speech act (e.g. "give me the toy or you're grounded") and labels them as exclusive. Finally, if negation is present in the sentence, the tree labels the disjunction as NOR. 

```{r wholeBaseline, fig.cap="The baseline tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.2. The tree uses the words \\textit{and/or} and classifies them as conjunction and exclusive disjunction."}
wholeBaseline <- readPNG("connective_modeling/whole_baselineTree.png")
grid::grid.raster(wholeBaseline)
```

```{r wholeCueBased, fig.asp=4, fig.cap="The cue-based tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.01. After using the words \\textit{and/or}, the tree uses intonation and consistency to classify a large number of exclusive cases. Then it uses utterance type (interrogative) to label many inclusive cases, as well as the communicative function (conditional) to catch more exclusive examples. Finally, it asks whether the sentence has negation or not. If so, it classifies the negative inlusive examples as NOR."}
wholeCueBased <- readPNG("connective_modeling/whole_cueBasedTree.png")
grid::grid.raster(wholeCueBased)
```

Figures \@ref(fig:ANDWhole), \@ref(fig:XORWhole), and \@ref(fig:IORWhole) show the average F1-scores for the conjunctive (AND), exclusive (XOR), and inclusive (IOR) interpretations as a function of training size. The results are similar to what wereported before with the ternary classification. While the cue-based model generally performs better than the baseline model, it shows substantial improvement in classifying inclusive cases. 

```{r ANDWhole, fig.cap="The average F1 score for class AND as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
AndWhole <- readPNG("connective_modeling/and-whole.png")
grid::grid.raster(AndWhole)
```

```{r XORWhole, fig.cap="The average F1 score for class XOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XorWhole <- readPNG("connective_modeling/xor-whole.png")
grid::grid.raster(XorWhole)
```

```{r IORWhole, fig.cap="The average F1 score for class IOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IorWhole <- readPNG("connective_modeling/ior-whole.png")
grid::grid.raster(IorWhole)
```

Figure \@ref(fig:NORWhole) shows the average F1-score for the negative inclusive interpretation as a function of training size. Compared to the baseline model, the cue-based model shows a substantially better performance in classifying negative sentences. The success of the model in classifying negative inclusive examples (NOR) suggests that the cue-based model offers a promising approach for capturing the scope relation of operators such as negation and disjunction. Here, the model learns that when negation and disjunction are present, the sentence receives a negative inclusive (NOR) interpretation. In other words, the model has learned the narrow-scope interpretation of negation and disjunction from the input data. In a language where negation and disjunction receive an XOR interpretation (not A or not B), the cue-based model can learn the wide-scope interpretation of disjunction. 

```{r NORWhole, fig.cap="The average F1 score for class NOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
NorWhole <- readPNG("connective_modeling/nor-whole.png")
grid::grid.raster(NorWhole)
```

Finally, Figure \@ref(fig:NPQWhole) shows the average F1 score for the class NPQ. This interpretation suggested that the first disjunct is false but the second true. It was seen in examples of repair most often and the most likely cue to it was also the communicative function or speech act of repair. The results show that even though there were improvements in the cue-based model, they were not stable as shown by the large confidence intervals. It is possible that with larger training samples, the cue-based model can reliably classify the NPQ interpretations as well.

```{r NPQWhole, fig.cap="The average F1 score for class NPQ as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
NpqWhole <- readPNG("connective_modeling/npq-whole.png")
grid::grid.raster(NpqWhole)
```

## Discussion

In this chapter, we discussed two accounts for the acquisition of function words. The first account was a baseline (context-independent) account that is used in vanilla cross-situational word learning: words are isolated and directly mapped to their most frequent meanings. The second account is what I called the cue-based context-dependent mapping in which words are mapped to meanings conditional on a set of present cues in the context. I argued that the puzzle of learning disjunction arises because in the baseline account, forms are mapped directly to meanings without considering the context of use. Under this account, the input statistics supports an exclusive interpretation for *or*. However, comprehension studies show that children can interpret *or* as inclusive. I showed that the cue-based account resolves this problem by allowing *or* to be mapped to its interpretation according to the set of contextual cues that disambiguate it. The results of computational experiments with decision tree learning on data from child-directed speech suggested that such an approach can successfully learn to classify a disjunction is inclusive or exclusive. More broadly, cue-based context-dependent mapping is useful for the acquisition of ambiguous words and interpretations that are consistent but relatively infrequent in child-directed speech. 

# Conclusion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

# Appendix

```{r logicalConnectives, fig.env="figure", fig.align="center", fig.width=5.5, fig.height=2.5, fig.cap="The truth table for the 16 binary logical connectives. The rows represent the set of situations where zero, one, or both propositions are true. The columns represent the 16 possible connectives and their truth conditions. Green cells represent true situations."}
binary_connectives<- png::readPNG("figs/binary_connective.png")
grid::grid.raster(binary_connectives)
```

## Annotation Categories

|Class|Meaning|Examples|
|-----|-------------------------------|------------------------------------------|
|AND|Both propositions are true| *"I'm just gonna empty this and then I'll be out of the kitchen." -- "I'll mix them together or I could mix it with carrot, too."*|
|IOR|One or both propositions are true| *"You should use a spoon or a fork." -- "Ask a grownup for some juice or water or soy milk."*|
|XOR|Only one proposition is true| *"Is that a hyena? or a leopard?" -- "We're gonna do things one way or the other."*|
|NOR|Neither proposition is true| *"I wouldn't say boo to one goose or three." -- "She found she lacked talent for hiding in trees, for chirping like crickets, or humming like bees."* |
|IFF|Either both propositions are true or both are false| *"Put them [crayons] up here and you can get down. -- Come over here and I'll show you."* |
|NAB|The first proposition is false, the second is true.| *"There's an Oatio here, or actually, there's a wheat here."* |
Table: (\#tab:connectiveInterpretaion) Annotation classes for connective interpretation

|Intonation|Definitions|Examples|
|--------|----------------------------------|--------------------------|
|Flat| Intonation does not show any substantial rise at the end of the sentence. | *"I don't hear any meows or bow-wow-wows."* |
|Rise| There is a substantial intonation rise on each disjunct or generally on both. | *"Do you want some seaweed? or some wheat germ?"*|
|Rise-Fall| There is a substantial rise on the non-final disjunct(s), and a fall on the final disjunct. | *"Is that big Q or little q?" -- "(are) You patting them, petting them, or slapping them?"* |
Table: (\#tab:intonationTypes) Definitions of the intonation types and their examples.

|Utterance Types|Definitions|Examples|
|---------------|------------------------------------|---------------------------|
|Declarative| A statement with a subject-verb-object word order and a flat intonation. | *"It looks a little bit like a drum stick or a mallet."*|
|Interrogative| A question with either subject-auxiliary inversion or a rising terminal intonation.  | *"Is that a dog or a cat?"*|
|Imperative| A directive with an uninflected verb and no subject | *"Have a little more French toast or have some of your juice."*|
Table: (\#tab:utteranceTypes) Definitions of the utterance types and their examples.

|Syntactic Level|Definitions|Examples|
|---------------|---------------------------------|---------------------------------|
|Clausal| The coordinands are sentences, clauses, verb phrases, or verbs. | *"Does he lose his tail sometimes and Pooh helps him and puts it back on?"*|
|Sub-clausal| The coordinands are nouns, adjectives, noun phrases, determiner phrases, or prepositional phrases.  | *"Hollies can be bushes or trees."*|
Table: (\#tab:syntacticLevel) Definitions of the syntactic levels and their examples.

|Consistency|Definitions|Examples|
|----------|-------------------|--------------------------------|
|Consistent| The coordinands can be true at the same time. | *"We could spell some things with a pen or draw some pictures."*|
|Inconsistent| The coordinands cannot be true at the same time.  | *"Do you want to stay or go?"*|
Table: (\#tab:consistencyType) Definitions of consistency types and their examples.

|Function|Definitions|Examples|
|-------------|--------------------------------------------|---------------------------------|
|Descriptions| Describing what the world is like or asking about it. The primary goal is to inform the addressee about how things are. |"*It's not in the ditch or the drain pipe.*"|
|Identifications| Identifying the category membership or an attribute of an object. Speaker has uncertainty. A subtype of "Description".| "*Is that a ball or a balloon honey?*"|
|Definitions and Examples| Providing labels for a category or examples for it. Speaker is certain. Subtype of Description.| *"This is a cup or a mug." -- "berries like blueberry or raspberry"*|
|Preferences| Asking what the addressee wants or would like or stating what the speaker wants or would like |*"Do you wanna play pizza or read the book?"* |
|Options| Either asking or listing what one can or is allowed to do. Giving permission, asking for permission, or describing the possibilities. Often the modal "can" is either present or can be inserted. | *"You could have wheat or rice."*|
|Directives| Directing the addressee to act or not act in a particular way. Common patterns include "let's do ...", "Why don't you do ...", or prohibitions such as "Don't ...". The difference with "options" is that the speaker expects the directive to be carried out by the addressee. There is no such expectation for "options".|*"let's go back and play with your ball or we'll read your book."* |
|Clarifications| Something is said or done as a communicative act but the speaker has uncertainty with respect to the form or the content.|*"You mean boba or bubble?"*|
|Repairs| Speaker correcting herself on something she said (self repair) or correcting the addressee (other repair). The second disjunct is what holds and is intended by the speaker. The speaker does not have uncertainty with respect to what actually holds. | *"There's an Oatio here, or actually, there's a wheat here."*|
|Conditionals| Explaining in the second coordinand, what would follow if the first coordinand is (or is not) followed. Subtype of Directive.| *"Put that out of your mouth, or I'm gonna put it away."* --  *"Come over here and I'll show you."*|
|Unconditionals| Denying the dependence of something on a set of conditions. Typical format: "Whether X or Y, Z". Subtype of Descriptions. | *"Ready or not, here I come!"* (playing hide and seek) |
Table: (\#tab:speechActs) Definitions of the communicative functions and their examples.

|Type|Definitions|Examples|
|-------------|--------------------------------|-------------------------|
|No Answer|The child provides no answer to the question.| Mother: *"Would you like to eat some applesauce or some carrots?"* Child: *"Guess what Max!"* |
|YN| The child responds with *yes* or *no*.| Father: *"Can I finish eating one or two more bites of my cereal?"* Child: *"No."* |
|AB| The child responds with one of the disjuncts (alternatives).| Mother: *"Is she a baby elephant or is she a toddler elephant?"* Child: *"It's a baby. She has a tail."*  |
Table: (\#tab:answerTypes) Definitions of answer types and their examples.

## Inter-annotator agreement

Figure \@ref(fig:oReliabilityPlot) shows the percentage agreement and the kappa values for each annotation category over the 8 iterations.

```{r oReliabilityPlot, fig.env="figure",fig.align="center", fig.width = 5.5, fig.cap="Inter-annotator agreement for disjunction examples."}
orAgreement <- 
  or_agreement %>%
  gather(annotation_category, value, Utterance.Type:Connective.Interpretation) 

ggplot(orAgreement, aes(x=iteration,y=value, color=annotation_category)) + 
  geom_line() + labs(y="Agreement", x="Iteration") + 
  geom_hline(yintercept=0.7) + 
  facet_grid(statistic~., scales="free_y") +
  theme_few() + 
  theme(text = element_text(size=11, family="Times")) + 
  scale_color_discrete(name = "Annotation Category")
```

Agreement in the following three categories showed substantial improvement after better and more precise definitions and annotation criteria were developed: connective interpretation, intonation, and communicative function. First, connective interpretation showed major improvements after annotators developed more precise criteria for selecting the propositions under discussion and separately wrote down the two propositions connected by the connective word. For example, if the original utterance was "do you want milk or juice?", the annotators wrote "you want milk, you want juice" as the two propositions under discussion. This exercise clarified the exact propositions under discussion and sharpened annotator intuitions with respect to the connective interpretation that is communicated by the utterance. Second, annotators improved agreement on intonation by reconstructing an utterance's intonation for all three intonation categories. For example, the annotator would examine the same sentence "do you want coffee or tea?" with a rise-fall, a rise, and a flat intonation. Then the annotator would listen to the actual utterance and see which one most resembled the actual utterance. This method helped annotators judge the intonation of an utterance more accurately. Finally, agreement on communicative functions improved as the definitions were made more precise. For example, the definition of "directives" in Table \@ref(tab:speechActs) explicitly mentions the difference between "directives" and "options". Clarifying the definitions of communicative functions helped improve annotator agreement. 

Inter-annotator reliability for conjunction was calculated in the same way. Two different annotators coded 300 utterances of *and*. Inter-annotator reliability was calculated over 10 iterations of 30 examples. Figure \@ref(fig:andReliabilityPlot) shows the percentage agreement between the annotators as well as the kappa values for each iteration.  Despite high percentage agreement between annotators, the kappa values did not pass the set threshold of 0.7 in three consecutive iterations. This paradoxical result is mainly due to a property of kappa. An imbalance in the prevalence of annotation categories can drastically lower its value. When one category is extremely common with high agreement while other categories are rare, kappa will be low [@cicchetti1990high;@feinstein1990high]. In almost all annotated categories for conjunction, there was one class that was extremely prevalent. In such cases, it is more informative to look at the class specific agreement for the prevalent category than the overall agreement measured by Kappa [@cicchetti1990high;@feinstein1990high]. 

```{r andReliabilityPlot, fig.align="center", fig.env="figure", fig.width = 5.5, fig.cap="Inter-annotator agreement for conjunction examples."}
andAgreement <- 
  and_agreement %>%
  gather(annotation_category, value, Utterance.Type:Connective.Interpretation) 

ggplot(andAgreement, aes(x=iteration,y=value, color=annotation_category)) + 
  geom_line() + labs(y="Agreement") + 
  geom_hline(yintercept=0.7) + 
  scale_x_continuous(breaks = seq(1,10)) +
  facet_grid(statistic~., scales="free_y") +
  theme_few() +
  theme(text = element_text(size=11, family="Times")) +
  scale_color_discrete(name = "Annotation Category")
```

Table \@ref(tab:andAgreeStats) lists the dominant classes as well as their prevalence, the values of class specific agreement index, and category agreement index (Kappa). Class specific agreement index is defined as $2n_{ii}/n_{i.}+n_{.i}$, where $i$ represents the class's row/column number in the category's confusion matrix, $n$ the number of annotations in a cell, and the dot ranges over all the row/column numbers [@fleiss2013statistical, page 600; @ubersax2009]. The class specific agreement indices are high for all the most prevalent classes showing that the annotators had very high agreement on these class, even though the general agreement index (Kappa) was often low. The most extreme case is the category "consistency" where almost all instances were annotated as "consistent" with perfect class specific agreement but low overall Kappa. In the case of utterance type and syntactic level where the distribution of instances across classes was more even, the general index of agreement Kappa is also high. In general, examples of conjunction showed little variability across annotation categories and mostly fell into one class within each category. Annotators had high agreement for these dominant classes.

```{r andAgreeStats}
and_specific_Kappa <- read_csv("connective_learning/3_providence_annotations/reliability/agreement/and_specific_Kappa.csv")

kable(and_specific_Kappa, digits=2, caption="Most prevalent annotation class in each annotation category with the values of class agreement indeces and category agreement indeces (Kappa).", col.names = c("Annotation Category", "Class", "Prevalence", "Class Agreement Index", "Kappa"))
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
