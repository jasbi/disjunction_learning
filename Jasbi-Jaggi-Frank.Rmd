---
title             : "Learning to Interpret a Disjunction"
shorttitle        : "Learning Disjunction"

author: 
  - name          : "Masoud Jasbi"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "masoud_jasbi@fas.harvard.edu"
  - name          : "Akshay Jaggi"
    affiliation   : "2"
  - name          : "Michael C. Frank"
    affiliation   : "2"

affiliation:
  - id            : "1"
    institution   : "Harvard University"
  - id            : "2"
    institution   : "Stanford University"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["JasbiJaggiFrank.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r global_options2, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, 
                      fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=TRUE, 
                      message=F, sanitize = T)
```

```{r bootstrapping}
## for bootstrapping 95% confidence intervals
theta <- function(x,xdata) {mean(xdata[x])}
ci.low <- function(x) {
  quantile(bootstrap(1:length(x),1000,theta,x)$thetastar,.025)}
ci.high <- function(x) {
  quantile(bootstrap(1:length(x),1000,theta,x)$thetastar,.975)}
```


```{r load_packages}
library("papaja")
library(tidyverse)
library(ggthemes)
library(lubridate)
library(magrittr)
library(kableExtra)
library(bootstrap)
library(lme4)
library(lmerTest)
library(jpeg)
library(png)
```

# Introduction

# Study 1: Disjunction in adult conversations

# Study 2: Disjunction in child-directed speech

```{r importProcessedData}
wordCounts <- read_csv("connective_learning/2_processed_data/wordCounts.csv")
wordCounts_byAge <- read_csv("connective_learning/2_processed_data/wordCounts_byAge.csv")

freqTable_bySpeaker <- read.csv("connective_learning/2_processed_data/relfreq_bySpeaker.csv")

freqTable_bySpeakerSpeechAct <- read.csv("connective_learning/2_processed_data/relfreq_bySpeakerSpeechAct.csv")

cnctv_prop_bySpeechAct <- read_csv("connective_learning/2_processed_data/connective_prop_bySpeechAct.csv")

freqTable_bySpeechAct <- read.csv("connective_learning/2_processed_data/frequency_bySpeechAct.csv")

freqTable_byAge <- read.csv("connective_learning/2_processed_data/RelFreq_byAge.csv")
freqTable_byAgeSpeechAct <- read.csv("connective_learning/2_processed_data/RelFreq_byAgeSpeechAct.csv")

relFreq_bySpeaker <- read.csv("connective_learning/2_processed_data/relFreq_bySpeaker.csv")

relFerq_bySpeakerSpeechAct <- read.csv("connective_learning/2_processed_data/relFerq_bySpeakerSpeechAct.csv")

utteranceType_bySpeaker <- read_csv("connective_learning/2_processed_data/utteranceType_bySpeaker.csv")

utteranceType_byAge <- read_csv("connective_learning/2_processed_data/utteranceType_byAge.csv")

wordCounts_byCollection <- read_csv("connective_learning/2_processed_data/wordCounts_byCollection.csv")

corpus_density <- read_csv("connective_learning/2_processed_data/corpusDensity.csv")
child_density <- read_csv("connective_learning/2_processed_data/childDensity.csv")
```

```{r corpusStats}
corpora_info <- read_csv("connective_learning/1_raw_data/corpora_info.csv")

# convert the ages into years
corpora_info$target_child_age_years <-
  corpora_info$target_child_age %>% duration("days") %>% as.numeric("years")

# children's ages
Ages <- 
  corpora_info$target_child_age_years %>% unique() %>% na.omit()

# number of transcripts after age exclusion
n_transcripts <- corpora_info %>% filter(target_child_age_years < 6, target_child_age_years > 1) %>% select(transcript_id) %>% unique()

n_transcripts <- length(n_transcripts$transcript_id)

exclusions <- read_csv("connective_learning/2_processed_data/exclusions.csv")
```

## Methods

For samples of parents' and children's speech, this study used the online database [childes-db](childes-db.stanford.edu) and its associated R programming package `childesr` [@sanchez2018childes]. Childes-db is an online interface to the child language components of [TalkBank](https://talkbank.org/), namely [CHILDES](https://childes.talkbank.org/) [@macwhinney2000childes] and [PhonBank](https://phonbank.talkbank.org/). Two collections of corpora were selected: English-North America and English-UK. All word tokens were tagged for the following information: 1. The speaker role (mother, father, child), 2. the age of the child when the word was produced, 3. the type of the utterance the word appeared in (declarative, question, imperative, other), and 4. whether the word was *and*, *or*, or neither.

```{r corpusDensityPlot, fig.width=6, fig.height=2.5, fig.align="center", fig.env="figure", fig.cap="Frequency for all the words in the North America and UK corpora of CHILDES."}
corpus_density %>%
  ggplot(aes(x=target_child_age_months, y=word_count, color=speaker_role)) +
  geom_line(stat="identity") +
  facet_grid(.~collection_name) +
  labs(x="age (months)", y="word count") +
  theme_few() +
  theme(text = element_text(size=11, family="Times")) +
  scale_color_discrete(name = "Speaker Role")
```

```{r childDensityPlot, fig.width=5, fig.height=2.5, fig.align="center", fig.env="figure", fig.cap="The number of children represented at different ages in the North America and UK corpora in CHILDES."}
child_density %>%
  ggplot(aes(x=target_child_age_months, y=child_count)) +
  geom_bar(stat="identity") +
  facet_grid(.~collection_name) +
  labs(x="age (months)", y="Number of Children") +
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

### Exclusion Criteria
First, observations (tokens) that were coded as unintelligible were excluded (N = `r format(exclusions$Unintelligible, big.mark=",")`). Second, observations that had missing information on children's age were excluded (N = `r format(exclusions$missing, big.mark=",")`). Third, observations outside the age range of 1 to 6 years were excluded (N = `r format(exclusions$age_ex, big.mark=",")`). This exclusion was mainly because there was not much data outside this age range. Figure \@ref(fig:ageDistPlot) shows the distribution of transcripts based on the age of the child at recording time. The mean age is shown with a red vertical line (Mean Age = `r round(mean(Ages),2)`, SD = `r round(sd(Ages),2)`). The collection contained the speech of `r exclusions$n_children` children and their parents after the exclusions. 

#### Procedure
Each token was marked for the utterance type that the token appeared in. This study grouped utterance types into four main categories: "declarative", "question", "imperative", and "other". Utterance type categorization followed the convention used in the [TalkBank manual](https://talkbank.org/manuals/CHAT.html#_Toc486414422). The utterance types are similar to sentence types (declarative, interrogative, imperative) with one exception: the category "question" consists of interrogatives as well as rising declaratives (i.e. declaratives with rising question intonation). In the transcripts, declaratives are marked with a period, questions with a question mark, and imperatives with an exclamation mark. It is important to note that the manual also provides [terminators for special-type utterances](https://talkbank.org/manuals/CHAT.html#_Toc486414431). Among the special type utterances, this study included the following in the category "questions": trailing off of a question, question with exclamation, interruption of a question, and self-interrupted question. The category imperatives also included "emphatic imperatives". The rest of the special type utterances such as "interruptions" and "trailing off" were included in the category "other".     

```{r ageDistPlot, fig.asp=0.5, fig.width=5, fig.height=3, fig.pos="center", fig.cap="Distribution of children's ages at recording times. Mean age is shown using a red vertical line."}
  par(family = "Times")
  hist(Ages, breaks = 50) 
  abline(v=mean(Ages),col="red", xlim=c(0,10))
  axis(side=1, at=seq(0,15, 1), labels=seq(0,15, 1))
```

### Properties of the CHILDES Corpora

```{r wordCount}
count_table <-
  wordCounts %>%
  select(-X1) %>%
  spread(word, counts) %>%
  mutate(total = and + or + other) %>%
  select(-other)

total_words <- sum(count_table$total)
```

In this section, I report some results on the distribution of words and utterances among the speakers in our collection of corpora. The collection contained `r format(total_words, big.mark = ",")` words. Table (\@ref(tab:countTable)) shows the total number of *and*'s, *or*'s, and words in the speech of children, fathers, and mothers. The collection contains  `r round(count_table$total[2]/count_table$total[1],1)` times more words for mothers compared to fathers and `r round(count_table$total[2]/count_table$total[3],1)` more words for mothers compared to children. Therefore, the collection is more representative of the mother-child interactions than father-child interactions. Compared to *or*, the word *and* is `r round(count_table$and[2]/count_table$or[2],1)` times more likely in the speech of mothers, `r round(count_table$and[1]/count_table$or[1],1)` times more likely in the speech of fathers, and `r round(count_table$and[3]/count_table$or[3],1)` times more likely in the speech of children. Overall, *and* is `r round(sum(count_table$and)/sum(count_table$or),2)` times more likely than *or* in this collection which is close to the rate reported by @morris2008logically. He extracted 5,994 instances of *and* and 465 instances of *or* and found that overall, *and* was 12.89 times more frequent than *or* in parent-child interactions.

```{r countTable}
kable(count_table, caption = "Number of \\textit{and}'s, \\textit{or}'s, and the total number of words in the speech of children and their parents in English-North America and English-UK collections after exclusions.", format.args = list(big.mark = ','), col.names = c("Speaker Role", "and", "or", "total"))
```

Figure \@ref(fig:wordsByAge) shows the number of words spoken by parents and children at each month of the child's development. The words in the collection are not distributed uniformly and there is a high concentration of data between the ages of 20 and 40 months (around 2 to 3 years of age). There is also a high concentration around 60 months (5 years of age). The speech of fathers shows a relatively low word-count across all ages. Therefore, in our analyses we should be more cautious in drawing conclusions about the speech of fathers generally, and the speech of mothers and children after age 5.

```{r wordsByAge, fig.env="figure", fig.align="center", fig.width=5, fig.height=2.5, fig.cap="The number of words in the corpora for parents and children in each month of children's development."}
wordCounts_byAge %>%
  ggplot(aes(x=target_child_age_months, y=count, color=speaker_role)) +
  geom_line(size=0.8) +
  labs(x="age (months)", y="number of words") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  theme_few() +
  theme(text = element_text(size=11, family="Times")) +
  scale_color_discrete(name = "Speaker Role")
```

The distribution of function words is sensitive to the type of utterance or more broadly the type of speech act produced by speakers. For example, it is not surprising to hear a parent say "go to your room" but a child saying the same to a parent is unexpected. If a function word commonly occurs in such speech acts, it is unlikely to be produced by children, even though they may understand it very well. Therefore, it is important to check the distribution of speech acts in corpora when studying different function words. Since it is hard to classify and quantify speech acts automatically, here I use utterance type as a proxy for speech acts. I investigate the distribution of declaratives, questions, and imperatives in this collection of corpora on parent-child interactions. Figure \@ref(fig:totalUtteranceTypePlot) shows the distribution of different utterance types in the speech of parents and children. Overall, most utterances are either declaratives or questions, and there are more declaratives than questions in this collection. While mothers and fathers show similar proportions of declaratives and questions in their speech, children produce a lower proportion of questions and higher proportion of declaratives than their parents.

```{r totalUtteranceTypePlot, fig.align="center", fig.width=4, fig.height=2, fig.cap="The proportion of declaratives and questions in children's and parents' utterances."}
utteranceType_bySpeaker %>%
#  filter(type == "declarative" | type == "question") %>%
  ggplot(aes(x=speaker_role, y=utteranceType_ppc, fill=speech_act)) + 
  theme(text = element_text(size=12)) +
  geom_bar(stat="identity") + labs(x="Speaker Role", y="Proportion (%)") + 
  theme_few() + theme(text = element_text(size = 11, family="Times")) +
  scale_fill_discrete(name = "Speech Act")
```

Figure \@ref(fig:utteranceTypeByAgePlot) shows the developmental trend of declaratives and questions between the ages of one and six. Children start with only producing declaratives and add non-declarative utterances to their repertoire gradually until they get closer to the parents' rate around the age six. They also start with very few questions and increase the number of questions they ask gradually. It is important to note that the rates of declaratives and questions in children's speech do not reach the adult rate. These two figures show that parent-child interactions are asymmetric. Parents ask more questions and children produce more declaratives. This asymmetry also interacts with age: the speech of younger children has a higher proportion of declaratives than older children.

```{r utteranceTypeByAgePlot, fig.width=5.5, fig.height=2.5, fig.cap = "Proportion of declaratives to questions in parent-child interactions by age."}
utteranceType_byAge %>%
  filter(speech_act == "declarative" | speech_act == "question") %>%
  ggplot(aes(x=target_child_age_months, y=utteranceType_ppc, shape=speaker_role, color = speaker_role)) +
  geom_point(aes(), size=0.6) + 
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +  
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue")) + 
  labs(x = "age (months)", y="Proportion (%)") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  facet_grid(.~speech_act) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

```{r utteranceTypeByAgePlot2, eval=FALSE}
utteranceType_byAge
utteranceType_byAge$Speaker <- "Parents"
utteranceType_byAge[utteranceType_byAge$speaker_role=="Target_Child",]$Speaker <- "Children"

utteranceType_byAge %>%
  filter(speech_act == "declarative" | speech_act == "question") %>%
  ggplot(aes(x=target_child_age_months, y=utteranceType_ppc, shape=Speaker, color = Speaker)) +
  geom_point(aes(), size=0.6) + 
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +  
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  labs(x = "age (months)", y="Proportion (%)") +
  scale_x_continuous(breaks=seq(12,72, 12)) +
  facet_grid(.~speech_act) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
```

The frequency of function words such as *and* and *or* may be affected by such conversational asymmetries if they are more likely to appear in some utterance types than others. Figure \@ref(fig:CnctPropbySpeechAct) shows the proportion of *and*'s and *or*'s that appear in different utterance types in parents' and children's speech. In parents' speech, *and* appears more often in declaratives (around 60% in declaratives and 20% in questions). On the other hand, *or* appears  more often in questions than declaratives, although this difference is small in mothers. In children's speech, both *and* and *or* appear most often in declaratives. However, children have a higher proportion of *or* in questions than *and* in questions. 

The differences in the distribution of utterance types can affect our interpretation of the corpus data on function words such as *and* and *or* in three ways. First, since the collection contains more declaratives than questions, it may reflect the frequency and diversity of function words like *and* that appear in declaratives better. Second, since children produce more declaratives and fewer questions than parents, we may underestimate children's knowledge of function words like *or* that are frequent in questions. Third, given that the percentage of questions in the speech of children increases as they get older, function words like *or* that are more likely to appear in questions may appear infrequent in the early stages and more frequent in the later stages of children's development. In other words, function words like *or* that are common in questions may show a seeming delay in production which is possibly due to the development of questions in children's speech. Therefore, in studying children's productions of function words, it is important to look at their relative frequencies in different utterance types as well as the overall trends. This is the approach I pursue in the next section.

```{r CnctPropbySpeechAct, fig.env="figure", fig.align="center", fig.width= 6, fig.height=3, fig.cap="The proportion of \\textit{and} and \\textit{or} in different utterance types in the speech of parents and children."}
cnctv_prop_bySpeechAct %>%
  filter(word != "other") %>%
  ggplot(aes(x=speech_act, y=connective_pct, fill=speech_act)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~speaker_role) + 
  theme_few() +
  geom_errorbar(aes(ymin=lower_pct, ymax=upper_pct), width=0.1) + 
  labs(x="", y="Proportion (%)") + 
#  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue", "gray")) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1), text = element_text(size=11, family="Times")) +
  guides(fill=FALSE)
```

<!--
### Properties of the Switchboard Corpus
-->
### Results {#study1results}

First, I consider the overall distribution of *and* and *or* in the corpora and then look closer at their distributions in different utterance types. Figure \@ref(fig:freqTableBySpeakerPlot) shows the frequency of *and* and *or* relative to the total number of words produced by each speaker (i.e. fathers, mothers, and children). The y-axes show relative frequency per thousand words. It is also important to note that the y-axes show different ranges of values for *and* vs. *or*. This is due to the large difference between the relative frequencies of these connectives. Overall, *and* occurs around 15 times per thousand words but *or* only occurs 3 times per 2000 words in the speech of parents and around 1 time every 2000 words in the speech of children. Comparing the relative frequency of the connectives in parents' and children's speech, we can see that overall, children and parents produce similar rates of *and* in their interactions. However, children produce fewer *or*'s than their parents. 

```{r freqTableBySpeakerPlot, fig.env="figure", fig.align="center", fig.width=3, fig.height=2.5, fig.cap="The relative frequency of \\textit{and/or} in the speech of fathers, mothers, and children. 95\\% binomial proportion confidence intervals calculated using Agresti-Coull's approximate method."}
freqTable_bySpeaker %>%
  filter(word != "other") %>%
  ggplot(aes(x=speaker_role, y=ppt, fill=speaker_role)) + 
  geom_bar(stat="identity", width = 0.7) + 
  facet_grid(word~., scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin = ppt_lower, ymax=ppt_upper), width=0.2) +
  labs(x="", y="Relative Frequency (per thaousand)") + 
  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue")) + 
  guides(fill=FALSE) + 
  theme(text = element_text(size=11, family="Times"))
```

```{r freqTablebySpeechAct2, eval=FALSE}
freqTable_bySpeaker$Speaker <- "Parents"
freqTable_bySpeaker[freqTable_bySpeaker$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_bySpeaker2 <-
freqTable_bySpeaker %>%
  group_by(Speaker, word) %>%
  summarize(count=sum(count), total=sum(total))

# calculating the confidence intervals
conf_ints <- 
  binom.confint(freqTable_bySpeaker2$count, freqTable_bySpeaker2$total, conf.level = 0.95, methods = "exact") %>%
  rename(total = "n", count="x", rel_freq = "mean") %>%
  select(-method)

#joining the confidence interval table and the proportion table
freqTable_bySpeaker2 %<>%
  full_join(conf_ints, by=c("count","total")) %>%
  mutate(ppt = rel_freq*1000, upper_ppt=upper*1000, lower_ppt=lower*1000)

freqTable_bySpeaker2 %>%
  filter(word != "other") %>%
  ggplot(aes(x=Speaker, y=ppt, fill=Speaker)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~., scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen", "darkblue")) + 
  theme(text = element_text(size=14, family="Times")) +
  guides(fill=FALSE)
```
Next we look at the relative frequencies of *and* and *or* in parents and children's speech during the course of children's development. Figure \@ref(fig:agePlot) shows the relative frequencies of *and* and *or* in parents' and children's speech between 12 and 72 months  (1-6 years). Production of *and* in parents' speech seems to be relatively stable and somewhere between 10 to 20 *and*'s per thousand words over the course of children's development. For children, they start producing *and* between 12 and 24 months, and show a sharp increase in their production until they reach the parent level between 30 to 36 months of age. Children stay close to the parents' production level between 36 and 72 months, possibly surpassing them a bit at 60 months -- although as stated in the previous section, we should be cautious about patterns after 60 months due to the small amount of data in this period. For *or*, parents produce between 1 to 2 *or*'s every thousand words and mothers show a slight increase in their productions between 12 to 36 months. Children start producing *or* between 18 to 30 months of age. They show a steady increase in their productions of *or* until they get close to 1 *or* per thousand words at 48 months (4 years) and  stay at that level until 72 months (6 years). 

Children's productions of *and* and *or* show two main differences. First, the onset of *or* production is later than that of *and*. Children start producing *and* around 1 to 1.5 years old while *or* productions start around 6 months later. Second, children's *and* production shows a steep rise and reaches the parent level of production at three-years old. For *or*, however, the rise in children's production level does not reach the parent level even though it seems to reach a constant level between the ages of 4 and 6 years. 

Not reaching the parent level of *or* production does not necessarily mean that children's understanding of *or* has not fully developed yet. It can also be due to the nature of parent-child interactions. For example, since parents ask more questions than children and *or* appears frequently in questions, parents may have a higher frequency of *or*. There are two ways of controlling for this possibility. One is to research children's speech to peers. Unfortunately such a large database of children's speech to peers is not currently available for analysis. Alternatively, we can look at the relative frequencies and developmental trends within utterance types such as declaratives and questions to see if we spot different developmental trends. This is what I pursue next.
\newline
```{r agePlot, fig.env="figure", fig.align="center", fig.width=4.5, fig.height=3.5, fig.cap="The monthly relative frequency of \\textit{and/or} in parents and children's speech between 12 and 72 months (1-6 years)."}
freqTable_byAge %>%
  filter(word!="other") %>%
  ggplot(aes(target_child_age_months, ppt, shape = speaker_role, color=speaker_role)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~., scales="free_y") +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "Age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme_few() + guides(shape=FALSE) +
  theme(text = element_text(size=11, family = "Times"))
```

```{r agePlot2, eval=FALSE}
freqTable_byAge$Speaker <- "Parents"
freqTable_byAge[freqTable_byAge$speaker_role=="Target_Child",]$Speaker <- "Children"


freqTable_byAge %>%
  filter(word!="other") %>%
  ggplot(aes(target_child_age_months, ppt, shape = Speaker, color=Speaker)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~., scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "Age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  theme_few() + guides(shape=FALSE) +
  theme(text = element_text(size=11, family = "Times"))
```

Figure \@ref(fig:freqTablebySpeechAct) shows the relative frequency of *and* and *or* in declaratives, questions, and imperatives. *And* has the highest relative frequency in declaratives while *or* has the highest relative frequency in questions. Figure \@ref(fig:ageSpeechActPlot) shows the developmental trends of the relative frequencies of *and* and *or* in questions and declaratives. Comparing *and* in declaratives and questions, we see that the onset of *and* productions are slightly delayed for questions but in both declaratives and questions, *and* productions reach the parent level around 36 months (3 years). For *or*, we see a similar delay in questions compared to declaratives. Children start producing *or* in declaratives at around 18 months but they start producing *or* in questions at 24 months. Production of *or* increases in both declaratives and questions until it seems to reach a constant rate in declaratives between 48 and 72 months. The relative frequency of *or* in questions continues to rise until 60 months. Comparing figures \@ref(fig:agePlot) and \@ref(fig:ageSpeechActPlot), we see that children are closer to the adult rate of production in declaratives than questions. The large difference between parents and children's production of *or* in figure \@ref(fig:agePlot) may partly be due to the development of *or* in questions. Overall the results show that children have a substantial increase in their productions of *and* and *or* between 1.5 to 4 years of age. Therefore, it is reasonable to expect that early mappings for the meaning and usage of these words develop in this age range. 

```{r freqTablebySpeechAct, fig.align="center", fig.width=5, fig.height=3, fig.cap="Relative frequency of \\textit{and/or} in declaratives, imperatives, and interrogatives for parents and children "}
freqTable_bySpeakerSpeechAct %>%
  filter(word != "other", speech_act!="other") %>%
  ggplot(aes(x=speech_act, y=ppt, fill=speaker_role)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~speaker_role, scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1), text = element_text(size=11, family="Times")) +
  guides(fill=FALSE)
```

```{r freqTablebySpeechAct22, eval=FALSE}
freqTable_bySpeakerSpeechAct$Speaker <- "Parents"
freqTable_bySpeakerSpeechAct[freqTable_bySpeakerSpeechAct$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_bSpeakerSpeechAct2 <-
freqTable_bySpeakerSpeechAct %>%
  group_by(Speaker, word, speech_act) %>%
  summarize(count=sum(count), total=sum(total))

# calculating the confidence intervals
conf_ints <- 
  binom.confint(freqTable_bSpeakerSpeechAct2$count, freqTable_bSpeakerSpeechAct2$total, conf.level = 0.95, methods = "exact") %>%
  rename(total = "n", count="x", rel_freq = "mean") %>%
  select(-method)

#joining the confidence interval table and the proportion table
freqTable_bSpeakerSpeechAct2 %<>%
  full_join(conf_ints, by=c("count","total")) %>%
  mutate(ppt = rel_freq*1000, upper_ppt=upper*1000, lower_ppt=lower*1000)

freqTable_bSpeakerSpeechAct2 %>%
  filter(word != "other", speech_act!="other") %>%
  ggplot(aes(x=speech_act, y=ppt, fill=Speaker)) + 
  geom_bar(stat="identity") + 
  facet_grid(word~Speaker, scales = "free_y") + theme_few() +
  geom_errorbar(aes(ymin=lower_ppt, ymax=upper_ppt), width=0.2) +
  labs(x="", y="relative frequency (per thousand)") + 
  scale_fill_manual(values = c("seagreen", "darkblue")) + 
  theme(text = element_text(size=14, family="Times")) +
  guides(fill=FALSE)
```

```{r ageSpeechActPlot, fig.env="figure", fig.align="center", fig.width=6, fig.height=4, fig.cap="Relative frequency of \\textit{and/or} in declaratives and questions for parents and childern between the child-age of 12 and 72 months (1-6 years)."}
freqTable_byAgeSpeechAct %>%
  filter(word!="other", speech_act!="other", speech_act!="imperative") %>%
  ggplot(aes(target_child_age_months, ppt, shape = speaker_role, color=speaker_role)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~speech_act, scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = speaker_role, color=speaker_role), span=1) +
  scale_color_manual(values = c("seagreen3","seagreen", "darkblue"), name="Speaker Role") + 
  theme_few() +
  theme(text = element_text(size=11, family="Times")) + 
  scale_shape_discrete(name = "Speaker Role")
```

```{r ageSpeechActPlot2, eval=FALSE}
freqTable_byAgeSpeechAct$Speaker <- "Parents"
freqTable_byAgeSpeechAct[freqTable_byAgeSpeechAct$speaker_role=="Target_Child",]$Speaker <- "Children"

freqTable_byAgeSpeechAct %>%
  filter(word!="other", speech_act!="other", speech_act!="imperative") %>%
  ggplot(aes(target_child_age_months, ppt, shape = Speaker, color=Speaker)) +
  geom_point(aes(), size=0.6) +
  facet_grid(word~speech_act, scales="free_y") +
#  scale_y_continuous(limits = c(0, 20)) +
  scale_x_continuous(breaks=seq(12,72, 6)) +
  labs(x = "age (months)", y="relative frequency (per thousand words)") +
  geom_smooth(aes(group = Speaker, color=Speaker), span=1) +
  scale_color_manual(values = c("seagreen", "darkblue")) + 
  theme_few() +
  theme(text = element_text(size=11, family="Times"))
#  guides(shape=FALSE, color=FALSE)
```

### Discussion {#study1discussion}

The goal of this study was to explore the frequency of *and* and *or* in parents and children's speech. The study found three differences. First, it found a difference between the overall frequency of *and* and *or* in both parents and children. *And* was about 10 times more frequent than *or* in the speech of parents and 30 times more likely in the speech of children. Second, the study found a difference between parents' and children's productions of *or*. Relative to the total number of words spoken by parents and children between the ages of 1 and 6 years, both children and parents produce on average 15 *and*'s every 1000 words. Therefore, children match parents' rate of *and* production overall. This is not the case for *or* as parents produce 3 *or*'s every 2000 words and children only 1 every 2000 words. Third, the study found a developmental difference between *and* and *or* as well. The study found that the onset of production is earlier for *and* than *or*. In the monthly relative frequencies of *and* and *or* in the speech of parents and children, the study also found that children reach the parents' level of production for *and* at age 3 while *or* does not reach the parents' level even at age 6. 

What causes these production differences? The first difference -- that *and* is far more frequent than *or* -- is not surprising or limited to child-directed speech. *And* is useful in a large set of contexts from conjoining elements of a sentence to connecting discourse elements or even holding the floor and delaying a conversational turn. In comparison, *or* seems to have a more limited usage. The second and the third differences -- namely that children produce fewer *or*'s than parents, and that they produce *and* and reach their parents rate earlier than *or* -- could be due to three factors. First, production of *and* develops and reaches the parents' rate earlier possibly because it is much more frequent than *or* in children's input. Previous research suggests that within the same syntactic category, words with higher frequency in child-directed speech are acquired earlier [@goodman2008does]. The conjunction word *and* is at least 10 times more likely than *or* so earlier acquisition of *and* is consistent with the effect of frequency on age of acquisition. Second, research on concept attainment has suggested that the concept of conjunction is easier to conjure and possibly acquire than the concept of disjunction. In experiments that participants are asked to detect a pattern in the classification of cards, participants can detect a conjunctive classification pattern faster than a disjunctive one [@neisser1962hierarchies]. Therefore, it is possible that children learn the meaning of *and* faster and start to produce it earlier but they need more time to figure out the meaning and usage of *or*.

A third possibility is that the developmental difference between *and* and *or* is mainly due to the asymmetric nature of parent-child interactions and the utterance types that each role in this interaction requires. For example, this study found that parents ask more questions of children than children do of parents. It also found that *or* is much more frequent in questions than *and* is. Therefore, parent-child interaction provides more opportunities for parents to use *or* than children. In the next study we will discuss several constructions and communicative functions that are also more appropriate for the role of parents. For example, *or* is often used to ask what someone else wants like "do you want apple juice or orange juice?" or for asking someone to clarify what they said such as "did you mean ball or bowl?". Both of these constructions are more likely to be produced by a parent than a child. *Or* is also used to introduce examples or provide definitions such as "an animal, like a rabbit, or a lion, or a sheep". It is very unlikely that children would use such constructions to define terms for parents! Furthermore, such constructions also reveal their own developmental trends. For example, the study found that children start by almost entirely producing declaratives and increase their questions until at age 4 to 6, about 10% of their utterances are questions. Therefore, children's ability to produce *or* in a question is subject to the development of questions themselves. More generally, the developmental difference between *and* and *or* may also be due to a difference in the development of other factors that production of *and* and *or* rely on, such as the development of constructions with specific communicative functions like unconditionals (Whether X or Y, discussed in Chapter \@ref(sempragLit)). In future research, it will be important to establish the extent to which each of these potential causes -- frequency, conceptual complexity, and the development of other factors such as utterance type or constructions with specific communicative functions --  contribute to the developmental differences in the production of conjunction and disjunction. 

# Study 3: Learning to interpret a disjunction

In Chapter \@ref(sempragLit), I reviewed the complexities involved in interpreting a disjunction word such as *or* in English. I showed that a disjunction can be interpreted as inclusive, exclusive, and even conjunctive. In addition to these truth-conditional interpretations, a disjunction is sometimes associated with speaker ignorance/indifference as well. Given the wide range of interpretations that *or* can have, how can children learn to interpret it correctly? 
This is what the current chapter will address. In doing so, it also provides a potential solution to the puzzle of learning disjunction mentioned in the Introduction. To recap the puzzle, previous corpus research as well as the study in Chapter \@ref(corpus), have shown that the majority of *or*-examples children hear are exclusive. However, comprehension studies report that between the ages of three and five, children can interpret *or* as inclusive disjunction in declarative sentences [@crain2012emergence]. The finding of the comprehension studies and the corpus studies taken together present a learning puzzle: how can children learn to interpret *or* as inclusive if they mostly hear exclusive examples? This chapter provides a solution by developing a cue-based account for children's acquisition of connectives. More generally, the account proposed in this chapter is helpful for learning words with multiple interpretations when one interpretation dominates the learner's input. 

Learning from multiple cues is a common approach in language acquisition [see @monaghan2014multiple, for an overview]. In the domain of function word semantics, @bloom1997linguistic proposed a cue-based account for the acquisition of number words. In the next section, I briefly review their proposal and report their findings. The annotation study in Chapter \@ref(corpus) used a methodology similar to that of @bloom1997linguistic and reported several cues that may help children's acquisition of the connectives *and* and *or*. In this section, I use the data in our annotation study to present a cue-based account of connective acquisition. This account provides a straightforward solution to the learning puzzle of disjunction. I provide support for the cue-based account using three modeling experiments. The models incorporate the proposed cues to learn decision trees that predict the interpretation of a disjunction/conjunction.

## The Cue-based Account for Number Words 

Research on children's acquisition of numeral words (e.g. *one*, *two*, *three*, etc.) has suggested that children initially know that number words greater than "one" refer to precise numerosities but they do not know exactly which word refers to which number [@wynn1992children]. @bloom1997linguistic searched for linguistic cues that could help children associate numerals with quantity and numerosity. They considered two classes of cues: syntactic and semantic. Syntactic cues to word meaning were first discussed by @brown1957linguistic. He wrote: "If a part of speech has reliable semantic implications, it could call attention to the kind of attribute likely to belong to the meaning of the word ... the part of speech membership of the new word could operate as a filter selecting for attention probably relevant features of the nonlinguistic world." He tested preschoolers with nonce constructions "to sib", "a sib", and "any sib" showing that children could use the modifying function words to decide whether the nonce word *sib* should refer to an action, an object, or a substance. 

Semantic cues, on the other hand, are provided by the meaning of the known words in the sentence. Consider the sentence "there were several gloobs." The use of *gloob* in the plural noun phrase "several gloobs" makes it possible to infer that "gloob" is not an action or a spatial relationship but rather an entity that can have multiple instances. Using only the syntactic cues, there still remains a wide range of referential uncertainty since a gloob may be anything from an egg to an alien creature. Now consider the sentence "I ate several gloobs for breakfast." What a gloob may be is now restricted to edible entities, probably those that are suitable for breakfast. The meanings of the verb *eat* and the adverbial phrase "for breakfast" help further narrow down the possible meanings for *gloob*. 

It is not always easy to tell whether a cue is syntactic or semantic. Here I avoid this issue by using the term "compositional cues" to refer to both syntactic and semantic cues that aid the interpretation of an unknown word. Using the term "compositional" also brings into attention the fact that syntactic and semantic cues are interrelated and do not act in an independent or unstructured way. Consider the sentence "After eating breakfast, I saw several gloobs." Even though the words *eat* and *breakfast* are present in the sentence, they do not restrict the possible meanings for *gloob* as they did before. In other words, it is not the mere presence of these words in the sentence that act as cues but rather the way they combine with the unknown word. The phrase "compositional cues" can help us highlight such important nuances.

@bloom1997linguistic proposed that children learn number word meanings by attending to the compositional cues that accompany number words such as the words' ordering relative to other words, function words they co-occur with, and the count-mass status of the nouns they modify. They specifically discussed four cues. Two cues could help children notice that number words pattern like quantifiers. First, similar to quantifiers, number words precede adjectives and do not follow them. Second, they participate in the "... of the Xs" construction: "one of the gloobs", "some of the gloobs", "most of the gloobs", etc. The third cue is the co-occurrence of number words with count nouns. This cue can inform learners that their meaning is restricted to the quantification of individuals. Finally, unlike other adjectives, numerals cannot be modified further using an adverb such as *very* or *too* ("very big animals" vs. "\*very two animals"). According to @bloom1997linguistic, this cue can help a learner understand that number words pick an absolute property of a set rather than a continuous one.

Using the data available in the CHILDES corpora, @bloom1997linguistic investigated the presence of cues to number-word meaning in child-directed speech for three children between the ages of one and three. They found that these children and their parents only use number words with count nouns; they do not use number words with modifiers and only use them before adjectives, not after. Finally, they found that these children and their parents use only number words and quantifiers in the partitive construction and not with adjectives. The results of their corpus study show that the compositional cues they proposed for number-word acquisition are available in children's linguistic input. In the next section, I discuss some compositional cues that can help a learner limit the hypothesis space to connective meanings for coordinators such as *and*, *or*, *but*, *so*, etc.

## Cues to coordinator meanings

```{r data_prep, echo=FALSE, warning=FALSE, message=FALSE}
alex_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-alex.csv", nrows=100)
lily_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-lily.csv", nrows=99)
vio_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-vio.csv", nrows=102)
will_data <- read.csv("connective_modeling/annotation_data/ProvidenceData-will.csv", nrows=100)
naima_data <- read.csv("connective_modeling/annotation_data/ProvidenceOR-Naima.csv", nrows=241)

naima_data <- 
  naima_data %>%
  filter(!is.na(exclusivity), !is.na(intonation))

all_data <- rbind(alex_data, lily_data, vio_data, will_data, naima_data)

all_data$intonation <- as.factor(all_data$intonation)

all_data$exclusion <- fct_recode(all_data$exclusion, "Consistent" = "ELS", "Inconsistent" = "EXC")
all_data$intonation <- fct_recode(all_data$intonation, "Flat" = "0", "Rising" = "1", "Rise-Fall" = "2")
all_data$intonation <- fct_recode(all_data$intonation, "Flat" = "0", "Rising" = "1", "Rise-Fall" = "2")
```

```{r data_wrangling, echo=FALSE, warning=FALSE, message=FALSE}
raw_data <- 
  all_data %>%
  group_by(id, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX) %>%
  gather(EXIN, counts, EX:IN) %>%
  mutate(prop = counts / total) %>%
  group_by(EXIN) %>%
  summarize(cih = ci.high(prop),
            cil = ci.low(prop),
            prop = mean(prop))

graph_data <- 
  all_data %>%
  group_by(id, intonation, exclusion, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = EX + IN) %>%
  gather(exclusivity, counts, EX:IN) %>%
  mutate(prop = counts / total) %>%
  group_by(exclusivity, intonation, exclusion) %>%
  summarize(cih = ci.high(prop),
            cil = ci.low(prop),
            prop = mean(prop)) 

counts_table<-  
  all_data %>%
  group_by(intonation, exclusion, syn_level, exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX)

exclusivity_overall <-
  all_data %>%
  group_by(exclusivity) %>%
  summarise(counts= n()) %>%
  spread(exclusivity, counts) %>%
  replace(is.na(.), 0) %>%
  mutate(total = IN + EX) %>%
  gather(exclusivity, counts, EX:IN) %>%
  mutate(prop = counts / total)

cds_disjunction_model <- summary(glmer(exclusivity ~ intonation + exclusion + (1|id), family="binomial", data=all_data))
```

```{r importSyntaxInfo}
annotations <- read_csv("connective_learning/3_providence_annotations/providence_merged.csv")

synTable <-
annotations %>%
  group_by(syn_level) %>%
  summarize(counts=n(), total = nrow(annotations), prop = counts/total)
```

Three important compositional cues can help learners in restricting their hypotheses to coordinator meanings. First, as pointed out by @haspelmath2007, coordination has specific compositional properties. Coordinators combine two or more units of the same type and return a larger unit of the same type. The larger unit has the same semantic relation with the surrounding words as the smaller units would have had without coordination. These properties separate coordinators from other function words such as articles, quantifiers, numerals, prepositions, and auxiliaries which are not used to connect sentences or any two similar units for that matter. In fact, the special syntactic properties of coordinators have compelled syntactic theories to consider specific rules for coordination.  

The literature on syntactic bootstrapping suggests that children can use syntactic properties of the input to limit their word meaning hypotheses to the relevant domain [@brown1957linguistic; @gleitman1990structural; see @fisher2010syntactic for a review]. In the current `r nrow(annotations)` annotations of conjunction and disjunction, I found that *and* and *or* connected sentences/clauses `r round(synTable$prop[2]*100)`% of the time. This pattern is unexpected for any other class of function words and it is possible that the syntactic distribution of coordinators cue the learners to the space of sentential connective meanings. 
<!--
Second, as mentioned in Chapter \@ref(corpus) as well, the concpetual relation between the propositions connected by a connective can also cue the connective meaning. For example, the propositions "falling off a bike" and "breaking an arm" have temporal and causal relations. One often happens before the other, and one is the cause of the other. Suppose I connect these two propositions using the made-up connective *yok*: "He fell off the bike yok broke his arm." A reasonable hypothesis is that *yok* signals the temporal and/or causal connection between these two events. This is what *and* often does in English. However, if I say "He broke his arm yok he fell off the bike", it is more probably that the connective *yok* -->

Second, in the annotation study I found that *and* never occurs with inconsistent coordinands (e.g. "clean and dirty") while *or* commonly does (e.g. "clean or dirty"). The inconsistency of the coordinands can cue the learner to not consider conjunction as a meaning for the coordinator given that a conjunctive meaning would too often lead to a contradiction at the utterance level. On the other hand, choosing disjunction as the meaning avoids this problem. Third, the large scale study of Chapter \@ref(corpus) found that *or* is more likely to occur in questions than statements while *and* is more likely in statements. Since questions often contain more uncertainty while statements are more informative, it is possible that these environments bias the learner towards selecting hypotheses that match this general communicative function. Disjunction is less informative than conjunction and it is possible that the frequent appearance of *or* in questions cues learners to both its meaning as a disjunction as well as the ignorance inference commonly associated with it.

Finally, it is reasonable to assume that not all binary connective meanings shown in Figure \@ref(fig:binaryLogicalConnectivess) are as likely for mapping. For example, coordinators that communicate tautologies or contradictions seem to be not good candidates for informative communication. Similarly, if A coordinated with B simply asserts the truth of A and says nothing about B, it is unclear why it would be needed if the language already has the means of simply asserting A. It is possible that pragmatic principles already bias the hypothesis space to favor candidates that are communicatively more efficient.

```{r binaryLogicalConnectivess, fig.env="figure", fig.align="center", fig.width=5, fig.height=2, fig.cap="The truth table for the 16 binary logical connectives. The rows represent the set of situations where zero, one, or both propositions are true. The columns represent the 16 possible connectives and their truth conditions. Green cells represent true situations."}
binary_connectives<- png::readPNG("figs/binary_connective.png")
grid::grid.raster(binary_connectives)
```

Even though these findings are suggestive, they need to be backed up by further observational and experimental evidence to show that children do actually use these cues in learning connective meanings. In the next section, I turn to the more specific issue of learning the correct interpretation of *and* and *or* from the input data. As in the case of number words, previous research has provided insight into how children comprehend a disjunction and what they hear from their parents. The main question is how children learn what they comprehend from what they hear. I turn to this issue in the next section.

## Learning to interpret *and* and *or*: A cue-based account {#myaccount}

Previous comprehension studies as well as the one reported in Chapter \@ref(comprehension) have shown that children as early as age three can interpret a disjunction as inclusive. However, Morris' [-@morris2008logically] study of child-directed speech showed that exclusive interpretations are much more common than other interpretations of disjunction in children's input. In Figure \@ref(fig:interpretation), I show the results of Chapter \@ref(corpus)'s annotation study by grouping the disjunction interpretations into exclusive (EX) and inclusive (IN), i.e. non-exclusive categories. These results replicate Morris' [-@morris2008logically] finding and reinforce a puzzle raised by @crain2012emergence: How can children learn the inclusive interpretation of disjunction when the majority of the examples they hear are exclusive? To answer this question, I draw on insights from the Gricean approach to semantics and pragmatics discussed in Chapter \@ref(sempragLit). 

```{r interpretation, fig.env='figure',fig.width=1.8, fig.height=1.8, fig.align="center",fig.cap = "Proportion of exclusive and inclusive interpretations of disjunction in child-directed speech. Error bars represent bootstrapped 95\\% confidence intervals."}
ggplot(raw_data, aes(x= EXIN, y=prop, fill=EXIN)) + 
  theme_few(base_size = 10) + 
  geom_col(width=0.7) +
  geom_linerange(aes(ymax = cih, ymin = cil)) + 
  guides(fill=FALSE) +
  labs(title = "", x = "", y = "Proportion") + 
  theme(text = element_text(family = "Times"))+
  scale_colour_solarized()
```

Research in Gricean semantics and pragmatics has shown that the word *or* is not the only factor relevant to the interpretation of a disjunction. It is not only the presence of the word *or* that leads us to interpret a disjunction as inclusive, exclusive, or conjunctive, but rather the presence of *or* along with several other factors such as intonation [@pruitt2013interpretation], the meaning of the disjuncts [@geurts2006exclusive], and the conversational principles governing communication [@grice1989studies]. The interpretation and acquisition of the word *or* cannot, therefore, be separated from all the factors that accompany it and shape its final interpretation. 

In the literature on word learning and semantic acquisition, form-meaning mapping is often construed as mapping an isolated form such as *gavagai* to an isolated concept such as "rabbit". While this approach may be feasible for content words, it will not work for function words such as *or*. First, the word *or* cannot be mapped in isolation from its formal context. As @pruitt2013interpretation showed, the intonation that accompanies a disjunction affects its interpretation. Therefore, a learner needs to pay attention to the word *or* as well as the intonation contour that accompanies it. Second, the word *or* cannot be mapped to its meaning isolated from the semantics of the disjuncts that accompany it. As @geurts2006exclusive argued, the exclusive interpretation is often enforced simply because the options are incompatible. For example, "to be or not to be" is exclusive simply because one cannot both be and not be. In addition, conversational factors play an important role in the interpretation of *or* as @grice1989studies argued. In sum, the interpretation and acquisition of function words such as *or* require the learner to consider the linguistic and nonlinguistic context of the word and map the meanings accordingly.

Previous accounts have adopted a model in which a function word such as *or* is mapped directly to its most likely interpretation: 

*or* $\rightarrow \oplus$

This model is often used in cross-situational accounts of content words. Here I argue that the direct mapping of *or* to its interpretation without consideration of its linguistic context is the primary cause of the learning puzzle for *or*. Instead, I propose that the word *or* is mapped to an interpretation in a context-dependent manner, along with the interpretive cues that accompany it such as intonation and disjunct semantics: 

[connective: *or*, Intonation: rise-fall, Disjuncts: inconsistent] $\rightarrow \oplus$

[connective: *or*, Intonation: rising, Disjuncts: consistent] $\rightarrow \lor$

Figure \@ref(fig:interpretationByIntonationAndConsistency) shows that the rate of exclusive interpretations change systematically when the data are broken down by intonation and consistency. Given a rise-fall intonation contour, a disjunction is almost always interpreted as exclusive. Similarly, if the propositions are inconsistent, the disjunction is most likely interpreted as exclusive. When either of these two features are absent, a disjunction is more likely to receive an inclusive interpretation.

```{r interpretationByIntonationAndConsistency, fig.env='figure', fig.width=3.5, fig.height=2.5, fig.align="center", fig.cap = "Exclusive and inclusive interpretations broken down by intonation (flat, rise, rise-fall) and consistency. Error bars represent bootstrapped 95\\% confidence intervals."}
ggplot(graph_data, aes(x= exclusivity, y=prop, fill=exclusivity)) + 
  geom_col(width=0.7) +
  geom_linerange(aes(ymax = cih, ymin = cil)) +
  guides(fill=FALSE) +
  theme_few(base_size = 10) + 
  labs(title = "", x = "", y = "Proportion") + 
  scale_colour_solarized() + facet_grid(exclusion~intonation) + theme(text = element_text(family = "Times"))
```

In this account, it is not a single word that gets mapped to an interpretation but rather a cluster of features. This method has two advantages. First, it deals with the context dependency of disjunction interpretation. The learner knows that *or* with some intonation has to be interpreted differently from one with another. Second, it allows the learner to pull apart the contribution of *or* from the interpretive cues that often accompany it. In fact, analysis of all mapping clusters in which *or* participates and generalization over them can help the learner extract the semantics of *or* the way it is intended by Gricean accounts of semantics/pragmatics. For those skeptical of such an underlying semantics for *or*, there is no need for further analysis of the mapping clusters. The meaning of *or* as a single lexical item is distributed among the many mappings in which it participates. In the next section, I implement this idea using decision tree learning.

## Modeling Using Decision Tree Learning {#DecisionTrees}

A decision tree is a classification model structured as a hierarchical tree with nodes, branches, and leaves [@breiman2017classification]. The tree starts with an initial node, called the root, and branches into more nodes until it reaches the leaves. Each node represents the test on a feature, each branch represents an outcome of the test, and each leaf represents a classification label. Using a decision tree, observations can be classified or labeled based on a set of features. For example, we can make a decision tree to predict whether a food item is a fruit or not based on its color (green or not) and shape (round or not). An example decision tree is the following: at the root, the model can ask whether the item is green or not. If yes, the model creates a leaf and labels the item as "not fruit". If not, the model creates another node and asks if the item is round. If yes, the item is classified as a "fruit" and if not it is classified as "not fruit". 

Decision trees have several advantages for modeling cue-based accounts of semantic acquisition. First, decision trees use a set of features to predict the classification of observations. This is analogous to using cues to predict the correct interpretation of a word or an utterance. Second, unlike many other machine learning techniques, decision trees result in models that are interpretable. Third, the order of decisions or features used for classification is determined based on information gain. Features that appear higher (earlier) in the tree are more informative and helpful for classification. Therefore, decision trees can help us understand which cues are probably more helpful for the acquisition and interpretation of a word.

Decision tree learning is the construction of a decision tree from labeled training data. This section applies decision tree learning to the annotated data of Chapter \@ref(corpus) by constructing random forests [@ho1995random; @breiman2001random]. In random classification forests multiple decision trees are constructed on subsets of the data and the decisions are made by taking the majority vote. Next section discusses the methods used in constructing the random forests for interpreting connectives *or*/*and*.

### Methods

The random forest models were constructed using python's Sci-kit Learn package [@pedregosa2011scikit]. The annotated data had a feature array and a connective interpretation label for each connective use. Connective interpretations included exclusive (XOR), inclusive (IOR), conjunctive (AND), negative inclusive (NOR), and NPQ which states that only the second proposition is true. The features or cues used included all other annotation categories: intonation, consistency, syntactic level, utterance type, and communicative function. All models were trained with stratified 10-Fold cross-validation to reduce overfitting. Stratified cross-validation maintains the distribution of the initial data in the random sampling to build cross validated models. Maintaining the data distribution ensures a more realistic learning environment for the forests. First a grid search was run on the hyperparamter space to establish the number of trees in each forest and the maximum tree depth allowable. The default number of trees for the forests was set to 20, with a max depth of eight and a minimum impurity decrease (i.e. gini decrease) of 0. Decision trees were fit with high and low minimum gini decrease values. High minimum gini decrease results in a tree that does not use any features for branching. Such a tree represents the baseline or traditional approach to mapping that directly maps a word to its most likely interpretation. Low minimum gini decrease allows for a less conservative tree that uses multiple cues/features to predict the interpretation of a disjunction. Such a tree represents the cue-based context-sensitive account of word learning discussed in the previous section. 

### Results

We first present the results of the random forests in the binary classification task. The models were trained to classify exclusive and inclusive interpretations of disjunction. Figure \@ref(fig:binaryBaseline) shows the best performing decision tree with high minimum gini decrease. As expected, a learner that does not use any cues would interpret *or* as exclusive all the time. This is the baseline model. Figure \@ref(fig:binaryCueBased) shows the best performing decision tree with low minimum gini decrease. The tree has learned to use intonation and consistency to classify disjunctions as exclusive or inclusive. As expected, if the intonation is rise-fall or the disjuncts are inconsistent, the interpretation is exclusive. Otherwise, the disjunction is classified as inclusive. 

```{r binaryBaseline, fig.asp=0.4, fig.cap="Baseline tree grown with minimum impurity decrease of 0.2. The tree always classifies examples of disjunction as exclusive."}
binaryBaseline <- readJPEG("connective_modeling/exin_baselineTree.jpg")
grid::grid.raster(binaryBaseline)
```

```{r binaryCueBased, fig.cap="Cue-based tree grown with minimum impurity decrease of 0.01. The tree classifies examples of disjunction with rise-fall intonation as exclusive (intonation > 1.5). If the intonation is not rise-fall but the disjuncts are inconsistent (consistency < 0.5), then the disjunction is still classified as exclusive. However, if neither of these two hold, the disjunction is classified as inclusive."}
binaryCueBased <- readJPEG("connective_modeling/exin_cueBasedTree.jpg")
grid::grid.raster(binaryCueBased)
```

Figure \@ref(fig:XorBinary) shows the average F1 scores of the baseline and cue-based models in classifying exclusive examples. The models perform relatively well and similar to each other, but the cue-based model performs slightly better. The real difference between the baseline model and the cue-based model is in their performance on inclusive examples. Figure \@ref(fig:IorBinary) shows the F1 score of the forests as a function of the training size in classifying inclusive examples. As expected, the baseline model performs very poorly while the cue-based model does a relatively good job and improves with more examples.

```{r XorBinary, fig.cap="The average F1 score for class XOR (exclusive) as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XorBinary <- readPNG("connective_modeling/ex-exin.png")
grid::grid.raster(XorBinary)
```

```{r IorBinary, fig.cap="The average F1 score for class IOR (inclusive) as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IorBinary <- readPNG("connective_modeling/in-exin.png")
grid::grid.raster(IorBinary)
```

Next, we use decision tree learning in a ternary classification task. The model uses features to interpret a coordination with *and* and *or* as inclusive (IOR), exclusive (XOR), or conjunctive (AND). Figure \@ref(fig:ternaryBaseline) shows the baseline decision tree with high minimum gini decrease, which only uses the presence of the words *or*/*and* to interpret conjunction and disjunction. As expected, the tree interprets a coordination with *and* as a conjunction and one with *or* as exclusive disjunction. Figure \@ref(fig:ternaryCueBased) shows the cue-based decision tree with low minimum gini decrease. In addition to the presence of *and* and *or*, the tree uses intonation, consistency, communicative function, and utterance type to distinguish exclusive, inclusive, and conjunctive uses of disjunction. In short, a disjunction that is rise-fall, inconsistent, or has a conditional communicative function is classified as exclusive. Otherwise the disjunction is classified as inclusive. The tree also finds conjunctive interpretations of disjunction more likely in declarative sentences than interrogatives.

```{r ternaryBaseline, fig.asp=0.6, fig.cap="The baseline tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.2. The tree uses the words \\textit{and/or} and classifies them as conjunction and exclusive disjunction respectively."}
ternaryBaseline <- readPNG("connective_modeling/intermediate_baselineTree.png")
grid::grid.raster(ternaryBaseline)
```

```{r ternaryCueBased, fig.asp=2.5, fig.cap="The cue-based tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.01. After using the words \\textit{and/or}, the tree uses intonation, consistency, and the conditional communicative function to classify a large number of exclusive cases. Then it uses utterance type (interrogative) to label inclusive cases."}
ternaryCueBased <- readPNG("connective_modeling/intermediate_cueBasedTree.png")
grid::grid.raster(ternaryCueBased)
```

Figure \@ref(fig:ANDintermediate) shows the average F1 score of the conjunctive interpretations (AND) for the baseline and the cue-based models. Since the vast majority of the conjunctive interpretations are predicted by the presence of the word *and*, the baseline and cue-based models show similar performances. Setting aside conjunction examples, Figure \@ref(fig:ANDintermediateDis) shows the average F1 score of the AND interpretation of disjunction only. Here we see that the cue-based model performs better than the default model in guessing conjunctive interpretations of disjunction. The informal analysis of the trees suggest that the model does this by using the "speech act" cue. Figure \@ref(fig:XORintermediate) shows the average F1-score of the exclusive interpretations (XOR) for the baseline and the cue-based models. The cue-based model does slightly better than the baseline model. As before, the most important improvement comes in identifying inclusive examples. Figure \@ref(fig:IORintermediate) shows the average F1-score of the inclusive interpretations (IOR) for both baseline and cue-based models. The baseline model performs very poorly while the cue-based model is capable of classifying inclusive examples as well.

```{r ANDintermediate, fig.cap="The average F1 score for class AND as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
ANDintermediate <- readPNG("connective_modeling/and-intermediate.png")
grid::grid.raster(ANDintermediate)
```

```{r ANDintermediateDis, fig.cap="The average F1 score for class AND of disjunction examles as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
ANDintermediateDis <- readPNG("connective_modeling/and-intermediate-disjunction.png")
grid::grid.raster(ANDintermediateDis)
```

```{r XORintermediate, fig.cap="The average F1 score for class XOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XORintermediate <- readPNG("connective_modeling/xor-intermediate.png")
grid::grid.raster(XORintermediate)
```

```{r IORintermediate, fig.cap="The average F1 score for class IOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IORintermediate <- readPNG("connective_modeling/ior-intermediate.png")
grid::grid.raster(IORintermediate)
```

Finally, welook at decision trees trained on the annotation data to predict all the interpretation classes for disjunction: AND, XOR, IOR, NOR, and NPQ. Figure \@ref(fig:wholeBaseline) shows the baseline model that only uses the words *and* and *or* to classify. As expected, *and* receives a conjunctive interpretation (AND) and *or* receives an exclusive interpretation (XOR). Figure \@ref(fig:wholeCueBased) shows the best example tree of the cue-based model. The leaves of the tree show that it recognizes exclusive, inclusive, conjunctive, and even negative inclusive (NOR) interpretations of disjunction. How does the tree achieve that? Like the baseline model, the tree first asks about the connective used: *and* vs. *or*. Then like the previous models, it asks about intonation and consistency. If the intonation is rise-fall, or the disjuncts are inconsistent, the interpretation is exclusive. Then it asks whether the sentence is an interrogative or a declarative. If interrogative, it guesses an inclusive interpretation. This basically covers questions with a rising intonation. Then the tree picks declarative examples that have conditional speech act (e.g. "give me the toy or you're grounded") and labels them as exclusive. Finally, if negation is present in the sentence, the tree labels the disjunction as NOR. 

```{r wholeBaseline, fig.cap="The baseline tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.2. The tree uses the words \\textit{and/or} and classifies them as conjunction and exclusive disjunction."}
wholeBaseline <- readPNG("connective_modeling/whole_baselineTree.png")
grid::grid.raster(wholeBaseline)
```

```{r wholeCueBased, fig.asp=4, fig.cap="The cue-based tree grown on conjunctions and disjunctions with minimum impurity decrease of 0.01. After using the words \\textit{and/or}, the tree uses intonation and consistency to classify a large number of exclusive cases. Then it uses utterance type (interrogative) to label many inclusive cases, as well as the communicative function (conditional) to catch more exclusive examples. Finally, it asks whether the sentence has negation or not. If so, it classifies the negative inlusive examples as NOR."}
wholeCueBased <- readPNG("connective_modeling/whole_cueBasedTree.png")
grid::grid.raster(wholeCueBased)
```

Figures \@ref(fig:ANDWhole), \@ref(fig:XORWhole), and \@ref(fig:IORWhole) show the average F1-scores for the conjunctive (AND), exclusive (XOR), and inclusive (IOR) interpretations as a function of training size. The results are similar to what wereported before with the ternary classification. While the cue-based model generally performs better than the baseline model, it shows substantial improvement in classifying inclusive cases. 

```{r ANDWhole, fig.cap="The average F1 score for class AND as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
AndWhole <- readPNG("connective_modeling/and-whole.png")
grid::grid.raster(AndWhole)
```

```{r XORWhole, fig.cap="The average F1 score for class XOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
XorWhole <- readPNG("connective_modeling/xor-whole.png")
grid::grid.raster(XorWhole)
```

```{r IORWhole, fig.cap="The average F1 score for class IOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
IorWhole <- readPNG("connective_modeling/ior-whole.png")
grid::grid.raster(IorWhole)
```

Figure \@ref(fig:NORWhole) shows the average F1-score for the negative inclusive interpretation as a function of training size. Compared to the baseline model, the cue-based model shows a substantially better performance in classifying negative sentences. The success of the model in classifying negative inclusive examples (NOR) suggests that the cue-based model offers a promising approach for capturing the scope relation of operators such as negation and disjunction. Here, the model learns that when negation and disjunction are present, the sentence receives a negative inclusive (NOR) interpretation. In other words, the model has learned the narrow-scope interpretation of negation and disjunction from the input data. In a language where negation and disjunction receive an XOR interpretation (not A or not B), the cue-based model can learn the wide-scope interpretation of disjunction. 

```{r NORWhole, fig.cap="The average F1 score for class NOR as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
NorWhole <- readPNG("connective_modeling/nor-whole.png")
grid::grid.raster(NorWhole)
```

Finally, Figure \@ref(fig:NPQWhole) shows the average F1 score for the class NPQ. This interpretation suggested that the first disjunct is false but the second true. It was seen in examples of repair most often and the most likely cue to it was also the communicative function or speech act of repair. The results show that even though there were improvements in the cue-based model, they were not stable as shown by the large confidence intervals. It is possible that with larger training samples, the cue-based model can reliably classify the NPQ interpretations as well.

```{r NPQWhole, fig.cap="The average F1 score for class NPQ as a function of the number of training examples in the baseline and cue-based models. The colored shades show the 95% confidence intervals."}
NpqWhole <- readPNG("connective_modeling/npq-whole.png")
grid::grid.raster(NpqWhole)
```

## Discussion

In this chapter, we discussed two accounts for the acquisition of function words. The first account was a baseline (context-independent) account that is used in vanilla cross-situational word learning: words are isolated and directly mapped to their most frequent meanings. The second account is what I called the cue-based context-dependent mapping in which words are mapped to meanings conditional on a set of present cues in the context. I argued that the puzzle of learning disjunction arises because in the baseline account, forms are mapped directly to meanings without considering the context of use. Under this account, the input statistics supports an exclusive interpretation for *or*. However, comprehension studies show that children can interpret *or* as inclusive. I showed that the cue-based account resolves this problem by allowing *or* to be mapped to its interpretation according to the set of contextual cues that disambiguate it. The results of computational experiments with decision tree learning on data from child-directed speech suggested that such an approach can successfully learn to classify a disjunction is inclusive or exclusive. More broadly, cue-based context-dependent mapping is useful for the acquisition of ambiguous words and interpretations that are consistent but relatively infrequent in child-directed speech. 

# Conclusion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

# Appendix

## Inter-annotator agreement

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
